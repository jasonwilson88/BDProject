2018-09-06 20:30:53,828 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = Jasons-MacBook-Pro.local/192.168.1.103
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 10.0.2
************************************************************/
2018-09-06 20:30:53,837 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-06 20:30:54,256 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-06 20:30:54,388 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-06 20:30:54,475 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-06 20:30:54,476 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-06 20:30:54,667 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-06 20:30:54,689 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 37022@Jasons-MacBook-Pro.local
2018-09-06 20:30:54,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-06 20:30:54,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-06 20:30:54,697 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-06 20:30:54,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-06 20:30:54,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-06 20:30:54,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-06 20:30:54,733 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 06 20:30:54
2018-09-06 20:30:54,734 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-06 20:30:54,734 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 20:30:54,734 INFO org.apache.hadoop.util.GSet: 2.0% max memory 1000 MB = 20 MB
2018-09-06 20:30:54,734 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-06 20:30:54,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-06 20:30:54,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-06 20:30:54,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-06 20:30:54,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-06 20:30:54,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-06 20:30:54,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-06 20:30:54,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-06 20:30:54,818 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-06 20:30:54,818 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 20:30:54,818 INFO org.apache.hadoop.util.GSet: 1.0% max memory 1000 MB = 10 MB
2018-09-06 20:30:54,818 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-06 20:30:54,820 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-06 20:30:54,820 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-06 20:30:54,820 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-06 20:30:54,827 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-06 20:30:54,827 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 20:30:54,828 INFO org.apache.hadoop.util.GSet: 0.25% max memory 1000 MB = 2.5 MB
2018-09-06 20:30:54,828 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-06 20:30:54,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-06 20:30:54,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-06 20:30:54,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-06 20:30:54,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-06 20:30:54,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-06 20:30:54,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-06 20:30:54,842 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-06 20:30:54,842 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-06 20:30:54,851 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-06 20:30:54,922 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-06 20:30:54,930 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-06 20:30:54,935 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-06 20:30:54,941 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-06 20:30:54,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-06 20:30:54,943 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-06 20:30:54,943 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-06 20:30:54,963 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-06 20:30:54,963 INFO org.mortbay.log: jetty-6.1.26
2018-09-06 20:30:55,017 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-06 20:30:55,017 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-06 20:31:55,222 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-06 20:31:55,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-06 20:31:55,446 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-06 20:31:55,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-06 20:31:55,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 322 bytes.
2018-09-06 20:31:55,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-06 20:31:55,672 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-06 20:31:55,672 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000005607853056 size 0 bytes.
2018-09-06 20:31:55,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-09-06 20:31:55,759 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-06 20:31:55,759 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000000
2018-09-06 20:31:55,759 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-06 20:31:55,766 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-06 20:31:55,772 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2018-09-06 20:31:55,772 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2018-09-06 20:31:55,787 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2018-09-06 20:31:55,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000002 using no compression
2018-09-06 20:31:55,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000002 of size 322 bytes saved in 0 seconds.
2018-09-06 20:31:55,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jason/dfs/namesecondary
2018-09-06 20:31:55,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jason/dfs/namesecondary
2018-09-06 20:31:55,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.045 seconds
2018-09-06 20:31:55,880 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 322
2018-09-06 21:17:57,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:17:58,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:17:59,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:00,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:01,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:02,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:03,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:04,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:05,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:06,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:18:06,446 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:18:06,455 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:19:07,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:08,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:09,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:10,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:11,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:12,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:13,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:14,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:15,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:16,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:19:16,508 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:19:16,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:20:17,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:18,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:19,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:20,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:21,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:22,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:23,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:24,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:25,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:26,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:20:26,552 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:20:26,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:21:27,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:28,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:29,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:30,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:31,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:32,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:33,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:34,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:35,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:36,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:21:36,776 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:21:36,778 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:22:37,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:38,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:39,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:40,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:41,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:42,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:43,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:44,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:45,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:46,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:22:46,817 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:22:47,010 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:23:48,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:49,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:50,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:51,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:52,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:53,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:54,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:55,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:56,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:57,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:23:57,046 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:23:57,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:24:58,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:24:59,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:00,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:01,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:02,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:03,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:04,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:05,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:06,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:07,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:25:07,088 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:25:07,299 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:26:08,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:09,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:10,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:11,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:12,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:13,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:14,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:15,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:16,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:17,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-06 21:26:17,346 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-06 21:26:17,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From Jasons-MacBook-Pro.local/192.168.1.103 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 21 more
2018-09-06 21:32:17,563 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-06 21:32:17,564 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3&endTxId=100&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-06 21:32:17,769 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 53894.74 KB/s
2018-09-06 21:32:17,770 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000100_0000000005611474953 size 0 bytes.
2018-09-06 21:32:17,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=101&endTxId=102&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-06 21:32:17,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-06 21:32:17,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000101-0000000000000000102_0000000005611475161 size 0 bytes.
2018-09-06 21:32:17,784 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2018-09-06 21:32:17,785 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000100 expecting start txid #3
2018-09-06 21:32:17,785 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000100
2018-09-06 21:32:17,836 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536283662720_0001/job.jar
2018-09-06 21:32:17,837 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536283662720_0001/job.split
2018-09-06 21:32:17,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000100 of size 1048576 edits # 98 loaded in 0 seconds
2018-09-06 21:32:17,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000101-0000000000000000102 expecting start txid #101
2018-09-06 21:32:17,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000101-0000000000000000102
2018-09-06 21:32:17,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000101-0000000000000000102 of size 42 edits # 2 loaded in 0 seconds
2018-09-06 21:32:17,855 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000102 using no compression
2018-09-06 21:32:17,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000102 of size 1548 bytes saved in 0 seconds.
2018-09-06 21:32:17,878 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2018-09-06 21:32:17,879 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-09-06 21:32:17,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 102 to namenode at http://localhost:50070 in 0.03 seconds
2018-09-06 21:32:17,912 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1548
2018-09-06 22:32:20,522 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-06 22:32:20,523 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=103&endTxId=109&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-06 22:32:20,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-06 22:32:20,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000103-0000000000000000109_0000000005615076039 size 0 bytes.
2018-09-06 22:32:20,538 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-06 22:32:20,538 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000103-0000000000000000109 expecting start txid #103
2018-09-06 22:32:20,538 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000103-0000000000000000109
2018-09-06 22:32:20,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000103-0000000000000000109 of size 344 edits # 7 loaded in 0 seconds
2018-09-06 22:32:20,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000109 using no compression
2018-09-06 22:32:20,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000109 of size 1736 bytes saved in 0 seconds.
2018-09-06 22:32:20,555 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 102
2018-09-06 22:32:20,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2018-09-06 22:32:20,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 109 to namenode at http://localhost:50070 in 0.026 seconds
2018-09-06 22:32:20,583 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-06 23:18:43,840 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-06 23:18:43,844 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at Jasons-MacBook-Pro.local/192.168.1.103
************************************************************/
2018-09-06 23:48:41,139 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = Jasons-MacBook-Pro.local/192.168.1.103
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 10.0.2
************************************************************/
2018-09-06 23:48:41,150 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-06 23:48:41,561 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-06 23:48:41,676 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-06 23:48:41,757 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-06 23:48:41,757 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-06 23:48:41,936 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-06 23:48:41,951 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 48411@Jasons-MacBook-Pro.local
2018-09-06 23:48:41,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-06 23:48:41,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-06 23:48:41,966 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-06 23:48:41,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-06 23:48:41,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-06 23:48:41,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-06 23:48:41,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 06 23:48:41
2018-09-06 23:48:41,998 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-06 23:48:41,998 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 23:48:41,998 INFO org.apache.hadoop.util.GSet: 2.0% max memory 1000 MB = 20 MB
2018-09-06 23:48:41,998 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-06 23:48:42,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-06 23:48:42,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-06 23:48:42,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-06 23:48:42,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-06 23:48:42,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-06 23:48:42,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-06 23:48:42,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-06 23:48:42,065 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-06 23:48:42,066 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 23:48:42,066 INFO org.apache.hadoop.util.GSet: 1.0% max memory 1000 MB = 10 MB
2018-09-06 23:48:42,066 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-06 23:48:42,068 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-06 23:48:42,068 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-06 23:48:42,068 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-06 23:48:42,072 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-06 23:48:42,072 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-06 23:48:42,073 INFO org.apache.hadoop.util.GSet: 0.25% max memory 1000 MB = 2.5 MB
2018-09-06 23:48:42,073 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-06 23:48:42,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-06 23:48:42,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-06 23:48:42,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-06 23:48:42,076 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-06 23:48:42,076 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-06 23:48:42,076 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-06 23:48:42,092 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-06 23:48:42,092 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-06 23:48:42,098 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-06 23:48:42,146 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-06 23:48:42,152 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-06 23:48:42,156 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-06 23:48:42,161 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-06 23:48:42,162 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-06 23:48:42,162 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-06 23:48:42,162 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-06 23:48:42,179 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-06 23:48:42,179 INFO org.mortbay.log: jetty-6.1.26
2018-09-06 23:48:42,237 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-06 23:48:42,238 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-06 23:49:42,464 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-06 23:49:42,623 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=110&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-06 23:49:42,657 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-06 23:49:42,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 62.50 KB/s
2018-09-06 23:49:42,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000110 size 1736 bytes.
2018-09-06 23:49:42,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=111&endTxId=112&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-06 23:49:42,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-06 23:49:42,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000111-0000000000000000112_0000000005619718418 size 0 bytes.
2018-09-06 23:49:42,984 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 20 INodes.
2018-09-06 23:49:43,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-06 23:49:43,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 110 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000110
2018-09-06 23:49:43,026 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-06 23:49:43,032 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-06 23:49:43,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112 expecting start txid #111
2018-09-06 23:49:43,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112
2018-09-06 23:49:43,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000111-0000000000000000112 of size 42 edits # 2 loaded in 0 seconds
2018-09-06 23:49:43,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000112 using no compression
2018-09-06 23:49:43,087 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000112 of size 1736 bytes saved in 0 seconds.
2018-09-06 23:49:43,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 110
2018-09-06 23:49:43,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000102, cpktTxId=0000000000000000102)
2018-09-06 23:49:43,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000109, cpktTxId=0000000000000000109)
2018-09-06 23:49:43,145 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 112 to namenode at http://localhost:50070 in 0.039 seconds
2018-09-06 23:49:43,146 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 01:49:37,682 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 01:49:37,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=113&endTxId=114&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 01:49:37,697 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 01:49:37,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000113-0000000000000000114_0000000005623319416 size 0 bytes.
2018-09-07 01:49:37,699 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 01:49:37,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000114 expecting start txid #113
2018-09-07 01:49:37,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000114
2018-09-07 01:49:37,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000113-0000000000000000114 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 01:49:37,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000114 using no compression
2018-09-07 01:49:37,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000114 of size 1736 bytes saved in 0 seconds.
2018-09-07 01:49:37,715 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 112
2018-09-07 01:49:37,715 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000110, cpktTxId=0000000000000000110)
2018-09-07 01:49:37,742 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 114 to namenode at http://localhost:50070 in 0.025 seconds
2018-09-07 01:49:37,742 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 02:49:38,640 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 02:49:38,641 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=115&endTxId=116&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 02:49:38,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 02:49:38,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000115-0000000000000000116_0000000005626920367 size 0 bytes.
2018-09-07 02:49:38,655 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 02:49:38,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000115-0000000000000000116 expecting start txid #115
2018-09-07 02:49:38,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000115-0000000000000000116
2018-09-07 02:49:38,656 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000115-0000000000000000116 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 02:49:38,656 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000116 using no compression
2018-09-07 02:49:38,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000116 of size 1736 bytes saved in 0 seconds.
2018-09-07 02:49:38,671 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 114
2018-09-07 02:49:38,671 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000112, cpktTxId=0000000000000000112)
2018-09-07 02:49:38,701 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 116 to namenode at http://localhost:50070 in 0.027 seconds
2018-09-07 02:49:38,701 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 03:49:39,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 03:49:39,236 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=117&endTxId=118&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 03:49:39,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 03:49:39,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000117-0000000000000000118_0000000005630521285 size 0 bytes.
2018-09-07 03:49:39,249 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 03:49:39,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118 expecting start txid #117
2018-09-07 03:49:39,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118
2018-09-07 03:49:39,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000117-0000000000000000118 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 03:49:39,250 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000118 using no compression
2018-09-07 03:49:39,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000118 of size 1736 bytes saved in 0 seconds.
2018-09-07 03:49:39,269 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 116
2018-09-07 03:49:39,269 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000114, cpktTxId=0000000000000000114)
2018-09-07 03:49:39,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 118 to namenode at http://localhost:50070 in 0.029 seconds
2018-09-07 03:49:39,302 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 04:49:40,179 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 04:49:40,179 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=119&endTxId=120&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 04:49:40,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 04:49:40,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000119-0000000000000000120_0000000005634122221 size 0 bytes.
2018-09-07 04:49:40,193 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 04:49:40,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000119-0000000000000000120 expecting start txid #119
2018-09-07 04:49:40,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000119-0000000000000000120
2018-09-07 04:49:40,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000119-0000000000000000120 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 04:49:40,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000120 using no compression
2018-09-07 04:49:40,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000120 of size 1736 bytes saved in 0 seconds.
2018-09-07 04:49:40,208 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 118
2018-09-07 04:49:40,208 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000116, cpktTxId=0000000000000000116)
2018-09-07 04:49:40,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 120 to namenode at http://localhost:50070 in 0.029 seconds
2018-09-07 04:49:40,239 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 05:49:40,964 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 05:49:40,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=121&endTxId=122&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 05:49:40,977 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 05:49:40,977 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000121-0000000000000000122_0000000005637722998 size 0 bytes.
2018-09-07 05:49:40,978 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 05:49:40,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000121-0000000000000000122 expecting start txid #121
2018-09-07 05:49:40,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000121-0000000000000000122
2018-09-07 05:49:40,979 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000121-0000000000000000122 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 05:49:40,979 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000122 using no compression
2018-09-07 05:49:40,983 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000122 of size 1736 bytes saved in 0 seconds.
2018-09-07 05:49:40,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 120
2018-09-07 05:49:40,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000118, cpktTxId=0000000000000000118)
2018-09-07 05:49:41,022 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 122 to namenode at http://localhost:50070 in 0.026 seconds
2018-09-07 05:49:41,023 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 06:49:41,783 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 06:49:41,785 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=123&endTxId=124&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 06:49:41,798 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 06:49:41,798 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000123-0000000000000000124_0000000005641323813 size 0 bytes.
2018-09-07 06:49:41,799 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 06:49:41,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000123-0000000000000000124 expecting start txid #123
2018-09-07 06:49:41,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000123-0000000000000000124
2018-09-07 06:49:41,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000123-0000000000000000124 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 06:49:41,800 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000124 using no compression
2018-09-07 06:49:41,803 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000124 of size 1736 bytes saved in 0 seconds.
2018-09-07 06:49:41,815 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 122
2018-09-07 06:49:41,815 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000120, cpktTxId=0000000000000000120)
2018-09-07 06:49:41,844 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 124 to namenode at http://localhost:50070 in 0.028 seconds
2018-09-07 06:49:41,844 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 07:49:42,703 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 07:49:42,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=125&endTxId=126&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 07:49:42,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 07:49:42,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000125-0000000000000000126_0000000005644924727 size 0 bytes.
2018-09-07 07:49:42,718 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 07:49:42,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000125-0000000000000000126 expecting start txid #125
2018-09-07 07:49:42,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000125-0000000000000000126
2018-09-07 07:49:42,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000125-0000000000000000126 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 07:49:42,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000126 using no compression
2018-09-07 07:49:42,723 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000126 of size 1736 bytes saved in 0 seconds.
2018-09-07 07:49:42,734 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 124
2018-09-07 07:49:42,734 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000122, cpktTxId=0000000000000000122)
2018-09-07 07:49:42,761 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 126 to namenode at http://localhost:50070 in 0.025 seconds
2018-09-07 07:49:42,761 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1736
2018-09-07 08:49:43,600 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 08:49:43,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=127&endTxId=128&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 08:49:43,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 08:49:43,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000127-0000000000000000128_0000000005648525619 size 0 bytes.
2018-09-07 08:49:43,614 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 08:49:43,614 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000127-0000000000000000128 expecting start txid #127
2018-09-07 08:49:43,614 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000127-0000000000000000128
2018-09-07 08:49:43,614 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000127-0000000000000000128 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 08:49:43,615 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000128 using no compression
2018-09-07 08:49:43,617 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000128 of size 1737 bytes saved in 0 seconds.
2018-09-07 08:49:43,627 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 126
2018-09-07 08:49:43,628 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000124, cpktTxId=0000000000000000124)
2018-09-07 08:49:43,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 128 to namenode at http://localhost:50070 in 0.029 seconds
2018-09-07 08:49:43,659 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1737
2018-09-07 16:55:02,011 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 16:55:02,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=129&endTxId=130&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 16:55:02,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 16:55:02,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000129-0000000000000000130_0000000005652163583 size 0 bytes.
2018-09-07 16:55:02,037 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 16:55:02,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000129-0000000000000000130 expecting start txid #129
2018-09-07 16:55:02,038 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000129-0000000000000000130
2018-09-07 16:55:02,039 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000129-0000000000000000130 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 16:55:02,041 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000130 using no compression
2018-09-07 16:55:02,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000130 of size 1737 bytes saved in 0 seconds.
2018-09-07 16:55:02,062 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 128
2018-09-07 16:55:02,062 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000126, cpktTxId=0000000000000000126)
2018-09-07 16:55:02,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 130 to namenode at http://localhost:50070 in 0.028 seconds
2018-09-07 16:55:02,093 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1737
2018-09-07 17:55:04,978 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 17:55:04,979 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=131&endTxId=132&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 17:55:04,992 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 17:55:04,992 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000131-0000000000000000132_0000000005655764460 size 0 bytes.
2018-09-07 17:55:04,993 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 17:55:04,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000131-0000000000000000132 expecting start txid #131
2018-09-07 17:55:04,994 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000131-0000000000000000132
2018-09-07 17:55:04,994 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000131-0000000000000000132 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 17:55:04,995 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000132 using no compression
2018-09-07 17:55:04,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000132 of size 1737 bytes saved in 0 seconds.
2018-09-07 17:55:05,010 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 130
2018-09-07 17:55:05,010 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000128, cpktTxId=0000000000000000128)
2018-09-07 17:55:05,042 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 132 to namenode at http://localhost:50070 in 0.028 seconds
2018-09-07 17:55:05,043 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1737
2018-09-07 19:54:59,533 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 19:54:59,535 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=133&endTxId=287&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 19:54:59,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1454.55 KB/s
2018-09-07 19:54:59,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000133-0000000000000000287_0000000005659365842 size 0 bytes.
2018-09-07 19:54:59,558 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 19:54:59,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000133-0000000000000000287 expecting start txid #133
2018-09-07 19:54:59,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000133-0000000000000000287
2018-09-07 19:54:59,764 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/temp470621848/tmp-1335653370/pig-0.16.0-core-h2.jar
2018-09-07 19:54:59,769 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/temp470621848/tmp-264287811/automaton-1.11-8.jar
2018-09-07 19:54:59,773 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/temp470621848/tmp1236910422/antlr-runtime-3.4.jar
2018-09-07 19:54:59,777 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/temp470621848/tmp-189690656/joda-time-2.9.3.jar
2018-09-07 19:54:59,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000133-0000000000000000287 of size 17044 edits # 155 loaded in 0 seconds
2018-09-07 19:54:59,899 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000287 using no compression
2018-09-07 19:54:59,912 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000287 of size 4746 bytes saved in 0 seconds.
2018-09-07 19:54:59,926 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 132
2018-09-07 19:54:59,926 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000130, cpktTxId=0000000000000000130)
2018-09-07 19:54:59,969 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 287 to namenode at http://localhost:50070 in 0.037 seconds
2018-09-07 19:54:59,970 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-07 21:54:52,418 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 21:54:52,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=288&endTxId=289&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 21:54:52,439 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 21:54:52,440 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000288-0000000000000000289_0000000005662967755 size 0 bytes.
2018-09-07 21:54:52,443 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 21:54:52,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000288-0000000000000000289 expecting start txid #288
2018-09-07 21:54:52,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000288-0000000000000000289
2018-09-07 21:54:52,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000288-0000000000000000289 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 21:54:52,446 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000289 using no compression
2018-09-07 21:54:52,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000289 of size 4746 bytes saved in 0 seconds.
2018-09-07 21:54:52,475 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 287
2018-09-07 21:54:52,475 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000132, cpktTxId=0000000000000000132)
2018-09-07 21:54:52,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 289 to namenode at http://localhost:50070 in 0.036 seconds
2018-09-07 21:54:52,518 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-07 23:54:46,904 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-07 23:54:46,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=290&endTxId=291&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-07 23:54:46,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-07 23:54:46,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000290-0000000000000000291_0000000005666569289 size 0 bytes.
2018-09-07 23:54:46,925 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-07 23:54:46,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000290-0000000000000000291 expecting start txid #290
2018-09-07 23:54:46,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000290-0000000000000000291
2018-09-07 23:54:46,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000290-0000000000000000291 of size 42 edits # 2 loaded in 0 seconds
2018-09-07 23:54:46,927 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000291 using no compression
2018-09-07 23:54:46,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000291 of size 4746 bytes saved in 0 seconds.
2018-09-07 23:54:46,951 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 289
2018-09-07 23:54:46,951 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000287, cpktTxId=0000000000000000287)
2018-09-07 23:54:46,991 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 291 to namenode at http://localhost:50070 in 0.034 seconds
2018-09-07 23:54:46,992 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 02:54:34,010 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 02:54:34,010 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=292&endTxId=293&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 02:54:34,030 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 02:54:34,031 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000292-0000000000000000293_0000000005670170663 size 0 bytes.
2018-09-08 02:54:34,033 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 02:54:34,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000292-0000000000000000293 expecting start txid #292
2018-09-08 02:54:34,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000292-0000000000000000293
2018-09-08 02:54:34,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000292-0000000000000000293 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 02:54:34,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000293 using no compression
2018-09-08 02:54:34,052 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000293 of size 4746 bytes saved in 0 seconds.
2018-09-08 02:54:34,070 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 291
2018-09-08 02:54:34,071 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000289, cpktTxId=0000000000000000289)
2018-09-08 02:54:34,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 293 to namenode at http://localhost:50070 in 0.039 seconds
2018-09-08 02:54:34,115 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 04:54:29,128 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 04:54:29,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=294&endTxId=295&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 04:54:29,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 04:54:29,143 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000294-0000000000000000295_0000000005673772268 size 0 bytes.
2018-09-08 04:54:29,144 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 04:54:29,144 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000294-0000000000000000295 expecting start txid #294
2018-09-08 04:54:29,144 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000294-0000000000000000295
2018-09-08 04:54:29,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000294-0000000000000000295 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 04:54:29,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000295 using no compression
2018-09-08 04:54:29,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000295 of size 4746 bytes saved in 0 seconds.
2018-09-08 04:54:29,161 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 293
2018-09-08 04:54:29,161 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000291, cpktTxId=0000000000000000291)
2018-09-08 04:54:29,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 295 to namenode at http://localhost:50070 in 0.031 seconds
2018-09-08 04:54:29,194 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 05:54:30,856 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 05:54:30,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=296&endTxId=297&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 05:54:30,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 05:54:30,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000296-0000000000000000297_0000000005677373846 size 0 bytes.
2018-09-08 05:54:30,882 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 05:54:30,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000296-0000000000000000297 expecting start txid #296
2018-09-08 05:54:30,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000296-0000000000000000297
2018-09-08 05:54:30,883 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000296-0000000000000000297 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 05:54:30,884 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000297 using no compression
2018-09-08 05:54:30,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000297 of size 4746 bytes saved in 0 seconds.
2018-09-08 05:54:30,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 295
2018-09-08 05:54:30,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000293, cpktTxId=0000000000000000293)
2018-09-08 05:54:30,957 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 297 to namenode at http://localhost:50070 in 0.037 seconds
2018-09-08 05:54:30,957 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 06:54:32,370 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 06:54:32,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=298&endTxId=299&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 06:54:32,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 06:54:32,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000298-0000000000000000299_0000000005680975352 size 0 bytes.
2018-09-08 06:54:32,393 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 06:54:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000298-0000000000000000299 expecting start txid #298
2018-09-08 06:54:32,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000298-0000000000000000299
2018-09-08 06:54:32,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000298-0000000000000000299 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 06:54:32,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000299 using no compression
2018-09-08 06:54:32,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000299 of size 4746 bytes saved in 0 seconds.
2018-09-08 06:54:32,421 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 297
2018-09-08 06:54:32,421 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000295, cpktTxId=0000000000000000295)
2018-09-08 06:54:32,468 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 299 to namenode at http://localhost:50070 in 0.037 seconds
2018-09-08 06:54:32,469 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 07:54:33,852 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 07:54:33,852 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=300&endTxId=301&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 07:54:33,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 07:54:33,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000300-0000000000000000301_0000000005684576821 size 0 bytes.
2018-09-08 07:54:33,873 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 07:54:33,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000300-0000000000000000301 expecting start txid #300
2018-09-08 07:54:33,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000300-0000000000000000301
2018-09-08 07:54:33,874 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000300-0000000000000000301 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 07:54:33,875 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000301 using no compression
2018-09-08 07:54:33,884 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000301 of size 4746 bytes saved in 0 seconds.
2018-09-08 07:54:33,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 299
2018-09-08 07:54:33,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000297, cpktTxId=0000000000000000297)
2018-09-08 07:54:33,947 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 301 to namenode at http://localhost:50070 in 0.038 seconds
2018-09-08 07:54:33,947 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 08:54:35,410 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 08:54:35,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=302&endTxId=303&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 08:54:35,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 08:54:35,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000302-0000000000000000303_0000000005688178370 size 0 bytes.
2018-09-08 08:54:35,433 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 08:54:35,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000302-0000000000000000303 expecting start txid #302
2018-09-08 08:54:35,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000302-0000000000000000303
2018-09-08 08:54:35,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000302-0000000000000000303 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 08:54:35,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000303 using no compression
2018-09-08 08:54:35,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000303 of size 4746 bytes saved in 0 seconds.
2018-09-08 08:54:35,458 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 301
2018-09-08 08:54:35,459 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000299, cpktTxId=0000000000000000299)
2018-09-08 08:54:35,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 303 to namenode at http://localhost:50070 in 0.038 seconds
2018-09-08 08:54:35,502 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 09:54:37,127 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 09:54:37,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=304&endTxId=305&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 09:54:37,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 09:54:37,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000304-0000000000000000305_0000000005691780079 size 0 bytes.
2018-09-08 09:54:37,151 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 09:54:37,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000304-0000000000000000305 expecting start txid #304
2018-09-08 09:54:37,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000304-0000000000000000305
2018-09-08 09:54:37,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000304-0000000000000000305 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 09:54:37,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000305 using no compression
2018-09-08 09:54:37,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000305 of size 4746 bytes saved in 0 seconds.
2018-09-08 09:54:37,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 303
2018-09-08 09:54:37,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000301, cpktTxId=0000000000000000301)
2018-09-08 09:54:37,226 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 305 to namenode at http://localhost:50070 in 0.038 seconds
2018-09-08 09:54:37,226 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 10:54:38,771 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 10:54:38,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=306&endTxId=307&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 10:54:38,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 10:54:38,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000306-0000000000000000307_0000000005695381715 size 0 bytes.
2018-09-08 10:54:38,796 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 10:54:38,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000306-0000000000000000307 expecting start txid #306
2018-09-08 10:54:38,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000306-0000000000000000307
2018-09-08 10:54:38,797 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000306-0000000000000000307 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 10:54:38,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000307 using no compression
2018-09-08 10:54:38,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000307 of size 4746 bytes saved in 0 seconds.
2018-09-08 10:54:38,821 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 305
2018-09-08 10:54:38,821 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000303, cpktTxId=0000000000000000303)
2018-09-08 10:54:38,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 307 to namenode at http://localhost:50070 in 0.04 seconds
2018-09-08 10:54:38,869 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 13:18:07,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 13:18:07,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=308&endTxId=309&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 13:18:07,401 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 13:18:07,401 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000308-0000000000000000309_0000000005698983168 size 0 bytes.
2018-09-08 13:18:07,404 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 13:18:07,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000308-0000000000000000309 expecting start txid #308
2018-09-08 13:18:07,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000308-0000000000000000309
2018-09-08 13:18:07,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000308-0000000000000000309 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 13:18:07,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000309 using no compression
2018-09-08 13:18:07,415 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000309 of size 4746 bytes saved in 0 seconds.
2018-09-08 13:18:07,430 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 307
2018-09-08 13:18:07,430 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000305, cpktTxId=0000000000000000305)
2018-09-08 13:18:07,472 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 309 to namenode at http://localhost:50070 in 0.036 seconds
2018-09-08 13:18:07,472 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 15:18:01,812 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 15:18:01,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=310&endTxId=311&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 15:18:01,829 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 15:18:01,829 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000310-0000000000000000311_0000000005702584520 size 0 bytes.
2018-09-08 15:18:01,831 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 15:18:01,831 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000310-0000000000000000311 expecting start txid #310
2018-09-08 15:18:01,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000310-0000000000000000311
2018-09-08 15:18:01,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000310-0000000000000000311 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 15:18:01,834 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000311 using no compression
2018-09-08 15:18:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000311 of size 4746 bytes saved in 0 seconds.
2018-09-08 15:18:01,862 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 309
2018-09-08 15:18:01,863 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000307, cpktTxId=0000000000000000307)
2018-09-08 15:18:01,907 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 311 to namenode at http://localhost:50070 in 0.036 seconds
2018-09-08 15:18:01,907 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 17:17:56,343 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 17:17:56,343 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=312&endTxId=313&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 17:17:56,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 17:17:56,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000312-0000000000000000313_0000000005706185901 size 0 bytes.
2018-09-08 17:17:56,362 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 17:17:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000312-0000000000000000313 expecting start txid #312
2018-09-08 17:17:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000312-0000000000000000313
2018-09-08 17:17:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000312-0000000000000000313 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 17:17:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000313 using no compression
2018-09-08 17:17:56,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000313 of size 4746 bytes saved in 0 seconds.
2018-09-08 17:17:56,389 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 311
2018-09-08 17:17:56,389 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000309, cpktTxId=0000000000000000309)
2018-09-08 17:17:56,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 313 to namenode at http://localhost:50070 in 0.035 seconds
2018-09-08 17:17:56,438 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 19:17:51,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 19:17:51,237 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=314&endTxId=315&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 19:17:51,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2018-09-08 19:17:51,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000314-0000000000000000315_0000000005709787500 size 0 bytes.
2018-09-08 19:17:51,265 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 19:17:51,265 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000314-0000000000000000315 expecting start txid #314
2018-09-08 19:17:51,265 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000314-0000000000000000315
2018-09-08 19:17:51,266 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000314-0000000000000000315 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 19:17:51,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000315 using no compression
2018-09-08 19:17:51,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000315 of size 4746 bytes saved in 0 seconds.
2018-09-08 19:17:51,291 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 313
2018-09-08 19:17:51,291 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000311, cpktTxId=0000000000000000311)
2018-09-08 19:17:51,342 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 315 to namenode at http://localhost:50070 in 0.045 seconds
2018-09-08 19:17:51,342 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 21:17:45,411 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 21:17:45,413 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=316&endTxId=317&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 21:17:45,431 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 21:17:45,431 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000316-0000000000000000317_0000000005713389124 size 0 bytes.
2018-09-08 21:17:45,434 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 21:17:45,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000316-0000000000000000317 expecting start txid #316
2018-09-08 21:17:45,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000316-0000000000000000317
2018-09-08 21:17:45,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000316-0000000000000000317 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 21:17:45,436 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000317 using no compression
2018-09-08 21:17:45,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000317 of size 4746 bytes saved in 0 seconds.
2018-09-08 21:17:45,480 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 315
2018-09-08 21:17:45,480 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000313, cpktTxId=0000000000000000313)
2018-09-08 21:17:45,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 317 to namenode at http://localhost:50070 in 0.036 seconds
2018-09-08 21:17:45,525 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-08 23:17:40,456 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-08 23:17:40,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=318&endTxId=319&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-08 23:17:40,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-08 23:17:40,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000318-0000000000000000319_0000000005716990821 size 0 bytes.
2018-09-08 23:17:40,479 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-08 23:17:40,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000318-0000000000000000319 expecting start txid #318
2018-09-08 23:17:40,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000318-0000000000000000319
2018-09-08 23:17:40,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000318-0000000000000000319 of size 42 edits # 2 loaded in 0 seconds
2018-09-08 23:17:40,481 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000319 using no compression
2018-09-08 23:17:40,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000319 of size 4746 bytes saved in 0 seconds.
2018-09-08 23:17:40,505 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 317
2018-09-08 23:17:40,505 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000315, cpktTxId=0000000000000000315)
2018-09-08 23:17:40,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 319 to namenode at http://localhost:50070 in 0.039 seconds
2018-09-08 23:17:40,555 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 01:17:34,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 01:17:34,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=320&endTxId=321&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 01:17:34,560 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 01:17:34,561 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000320-0000000000000000321_0000000005720592233 size 0 bytes.
2018-09-09 01:17:34,562 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 01:17:34,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000320-0000000000000000321 expecting start txid #320
2018-09-09 01:17:34,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000320-0000000000000000321
2018-09-09 01:17:34,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000320-0000000000000000321 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 01:17:34,565 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000321 using no compression
2018-09-09 01:17:34,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000321 of size 4746 bytes saved in 0 seconds.
2018-09-09 01:17:34,588 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 319
2018-09-09 01:17:34,588 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000317, cpktTxId=0000000000000000317)
2018-09-09 01:17:34,632 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 321 to namenode at http://localhost:50070 in 0.038 seconds
2018-09-09 01:17:34,633 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 04:17:21,271 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 04:17:21,271 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=322&endTxId=323&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 04:17:21,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 04:17:21,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000322-0000000000000000323_0000000005724193465 size 0 bytes.
2018-09-09 04:17:21,285 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 04:17:21,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000322-0000000000000000323 expecting start txid #322
2018-09-09 04:17:21,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000322-0000000000000000323
2018-09-09 04:17:21,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000322-0000000000000000323 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 04:17:21,287 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000323 using no compression
2018-09-09 04:17:21,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000323 of size 4746 bytes saved in 0 seconds.
2018-09-09 04:17:21,300 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 321
2018-09-09 04:17:21,300 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000319, cpktTxId=0000000000000000319)
2018-09-09 04:17:21,330 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 323 to namenode at http://localhost:50070 in 0.027 seconds
2018-09-09 04:17:21,330 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 05:17:23,450 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 05:17:23,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=324&endTxId=325&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 05:17:23,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 05:17:23,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000324-0000000000000000325_0000000005727795002 size 0 bytes.
2018-09-09 05:17:23,474 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 05:17:23,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000324-0000000000000000325 expecting start txid #324
2018-09-09 05:17:23,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000324-0000000000000000325
2018-09-09 05:17:23,475 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000324-0000000000000000325 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 05:17:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000325 using no compression
2018-09-09 05:17:23,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000325 of size 4746 bytes saved in 0 seconds.
2018-09-09 05:17:23,509 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 323
2018-09-09 05:17:23,509 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000321, cpktTxId=0000000000000000321)
2018-09-09 05:17:23,558 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 325 to namenode at http://localhost:50070 in 0.04 seconds
2018-09-09 05:17:23,558 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 06:17:25,121 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 06:17:25,123 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=326&endTxId=327&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 06:17:25,141 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 06:17:25,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000326-0000000000000000327_0000000005731396665 size 0 bytes.
2018-09-09 06:17:25,144 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 06:17:25,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000326-0000000000000000327 expecting start txid #326
2018-09-09 06:17:25,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000326-0000000000000000327
2018-09-09 06:17:25,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000326-0000000000000000327 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 06:17:25,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000327 using no compression
2018-09-09 06:17:25,161 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000327 of size 4746 bytes saved in 0 seconds.
2018-09-09 06:17:25,177 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 325
2018-09-09 06:17:25,177 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000323, cpktTxId=0000000000000000323)
2018-09-09 06:17:25,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 327 to namenode at http://localhost:50070 in 0.039 seconds
2018-09-09 06:17:25,221 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 07:17:26,687 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 07:17:26,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=328&endTxId=329&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 07:17:26,705 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 07:17:26,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000328-0000000000000000329_0000000005734998220 size 0 bytes.
2018-09-09 07:17:26,708 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 07:17:26,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000328-0000000000000000329 expecting start txid #328
2018-09-09 07:17:26,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000328-0000000000000000329
2018-09-09 07:17:26,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000328-0000000000000000329 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 07:17:26,711 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000329 using no compression
2018-09-09 07:17:26,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000329 of size 4746 bytes saved in 0 seconds.
2018-09-09 07:17:26,734 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 327
2018-09-09 07:17:26,734 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000325, cpktTxId=0000000000000000325)
2018-09-09 07:17:26,784 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 329 to namenode at http://localhost:50070 in 0.044 seconds
2018-09-09 07:17:26,784 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 08:17:28,248 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 08:17:28,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=330&endTxId=331&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 08:17:28,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 08:17:28,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000330-0000000000000000331_0000000005738599772 size 0 bytes.
2018-09-09 08:17:28,270 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 08:17:28,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000330-0000000000000000331 expecting start txid #330
2018-09-09 08:17:28,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000330-0000000000000000331
2018-09-09 08:17:28,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000330-0000000000000000331 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 08:17:28,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000331 using no compression
2018-09-09 08:17:28,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000331 of size 4746 bytes saved in 0 seconds.
2018-09-09 08:17:28,295 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 329
2018-09-09 08:17:28,295 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000327, cpktTxId=0000000000000000327)
2018-09-09 08:17:28,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 331 to namenode at http://localhost:50070 in 0.042 seconds
2018-09-09 08:17:28,350 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 09:17:29,731 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 09:17:29,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=332&endTxId=333&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 09:17:29,750 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 09:17:29,751 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000332-0000000000000000333_0000000005742201247 size 0 bytes.
2018-09-09 09:17:29,754 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 09:17:29,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000332-0000000000000000333 expecting start txid #332
2018-09-09 09:17:29,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000332-0000000000000000333
2018-09-09 09:17:29,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000332-0000000000000000333 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 09:17:29,757 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000333 using no compression
2018-09-09 09:17:29,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000333 of size 4746 bytes saved in 0 seconds.
2018-09-09 09:17:29,779 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 331
2018-09-09 09:17:29,779 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000329, cpktTxId=0000000000000000329)
2018-09-09 09:17:29,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 333 to namenode at http://localhost:50070 in 0.041 seconds
2018-09-09 09:17:29,828 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 10:17:31,153 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 10:17:31,155 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=334&endTxId=335&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 10:17:31,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 10:17:31,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000334-0000000000000000335_0000000005745802665 size 0 bytes.
2018-09-09 10:17:31,176 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 10:17:31,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000334-0000000000000000335 expecting start txid #334
2018-09-09 10:17:31,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000334-0000000000000000335
2018-09-09 10:17:31,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000334-0000000000000000335 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 10:17:31,179 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000335 using no compression
2018-09-09 10:17:31,185 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000335 of size 4746 bytes saved in 0 seconds.
2018-09-09 10:17:31,199 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 333
2018-09-09 10:17:31,199 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000331, cpktTxId=0000000000000000331)
2018-09-09 10:17:31,247 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 335 to namenode at http://localhost:50070 in 0.035 seconds
2018-09-09 10:17:31,247 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 11:17:32,721 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 11:17:32,723 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=336&endTxId=337&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 11:17:32,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 11:17:32,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000336-0000000000000000337_0000000005749404226 size 0 bytes.
2018-09-09 11:17:32,744 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 11:17:32,744 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000337 expecting start txid #336
2018-09-09 11:17:32,744 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000337
2018-09-09 11:17:32,745 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000337 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 11:17:32,747 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000337 using no compression
2018-09-09 11:17:32,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000337 of size 4746 bytes saved in 0 seconds.
2018-09-09 11:17:32,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 335
2018-09-09 11:17:32,771 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000333, cpktTxId=0000000000000000333)
2018-09-09 11:17:32,817 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 337 to namenode at http://localhost:50070 in 0.039 seconds
2018-09-09 11:17:32,817 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 12:17:34,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 12:17:34,204 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=338&endTxId=339&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 12:17:34,222 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 12:17:34,222 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000338-0000000000000000339_0000000005753005701 size 0 bytes.
2018-09-09 12:17:34,225 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 12:17:34,225 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000338-0000000000000000339 expecting start txid #338
2018-09-09 12:17:34,225 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000338-0000000000000000339
2018-09-09 12:17:34,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000338-0000000000000000339 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 12:17:34,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000339 using no compression
2018-09-09 12:17:34,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000339 of size 4746 bytes saved in 0 seconds.
2018-09-09 12:17:34,253 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 337
2018-09-09 12:17:34,253 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000335, cpktTxId=0000000000000000335)
2018-09-09 12:17:34,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 339 to namenode at http://localhost:50070 in 0.035 seconds
2018-09-09 12:17:34,295 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 13:17:35,729 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 13:17:35,732 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=340&endTxId=341&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 13:17:35,750 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 13:17:35,750 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000340-0000000000000000341_0000000005756607220 size 0 bytes.
2018-09-09 13:17:35,753 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 13:17:35,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000340-0000000000000000341 expecting start txid #340
2018-09-09 13:17:35,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000340-0000000000000000341
2018-09-09 13:17:35,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000340-0000000000000000341 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 13:17:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000341 using no compression
2018-09-09 13:17:35,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000341 of size 4746 bytes saved in 0 seconds.
2018-09-09 13:17:35,779 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 339
2018-09-09 13:17:35,779 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000337, cpktTxId=0000000000000000337)
2018-09-09 13:17:35,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 341 to namenode at http://localhost:50070 in 0.036 seconds
2018-09-09 13:17:35,821 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 15:17:30,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 15:17:30,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=342&endTxId=343&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 15:17:30,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 15:17:30,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000342-0000000000000000343_0000000005760208607 size 0 bytes.
2018-09-09 15:17:30,133 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 15:17:30,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000342-0000000000000000343 expecting start txid #342
2018-09-09 15:17:30,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000342-0000000000000000343
2018-09-09 15:17:30,134 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000342-0000000000000000343 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 15:17:30,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000343 using no compression
2018-09-09 15:17:30,144 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000343 of size 4746 bytes saved in 0 seconds.
2018-09-09 15:17:30,156 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 341
2018-09-09 15:17:30,157 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000339, cpktTxId=0000000000000000339)
2018-09-09 15:17:30,202 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 343 to namenode at http://localhost:50070 in 0.03 seconds
2018-09-09 15:17:30,202 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 16:36:00,178 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 16:36:00,184 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=344&endTxId=345&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 16:36:00,216 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 16:36:00,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000344-0000000000000000345_0000000005763809806 size 0 bytes.
2018-09-09 16:36:00,218 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 16:36:00,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000344-0000000000000000345 expecting start txid #344
2018-09-09 16:36:00,219 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000344-0000000000000000345
2018-09-09 16:36:00,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000344-0000000000000000345 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 16:36:00,222 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000345 using no compression
2018-09-09 16:36:00,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000345 of size 4746 bytes saved in 0 seconds.
2018-09-09 16:36:00,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 343
2018-09-09 16:36:00,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000341, cpktTxId=0000000000000000341)
2018-09-09 16:36:00,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 345 to namenode at http://localhost:50070 in 0.029 seconds
2018-09-09 16:36:00,283 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 17:36:01,238 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 17:36:01,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=346&endTxId=347&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 17:36:01,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 17:36:01,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000346-0000000000000000347_0000000005767410853 size 0 bytes.
2018-09-09 17:36:01,256 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 17:36:01,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000346-0000000000000000347 expecting start txid #346
2018-09-09 17:36:01,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000346-0000000000000000347
2018-09-09 17:36:01,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000346-0000000000000000347 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 17:36:01,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000347 using no compression
2018-09-09 17:36:01,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000347 of size 4746 bytes saved in 0 seconds.
2018-09-09 17:36:01,274 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 345
2018-09-09 17:36:01,274 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000343, cpktTxId=0000000000000000343)
2018-09-09 17:36:01,317 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 347 to namenode at http://localhost:50070 in 0.03 seconds
2018-09-09 17:36:01,317 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 18:36:03,674 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 18:36:03,679 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=348&endTxId=349&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 18:36:03,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 18:36:03,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000348-0000000000000000349_0000000005771011851 size 0 bytes.
2018-09-09 18:36:03,699 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 18:36:03,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000348-0000000000000000349 expecting start txid #348
2018-09-09 18:36:03,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000348-0000000000000000349
2018-09-09 18:36:03,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000348-0000000000000000349 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 18:36:03,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000349 using no compression
2018-09-09 18:36:03,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000349 of size 4746 bytes saved in 0 seconds.
2018-09-09 18:36:03,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 347
2018-09-09 18:36:03,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000345, cpktTxId=0000000000000000345)
2018-09-09 18:36:03,758 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 349 to namenode at http://localhost:50070 in 0.028 seconds
2018-09-09 18:36:03,758 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 19:36:04,602 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 19:36:04,603 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=350&endTxId=351&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 19:36:04,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 19:36:04,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000350-0000000000000000351_0000000005774612764 size 0 bytes.
2018-09-09 19:36:04,619 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 19:36:04,619 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000350-0000000000000000351 expecting start txid #350
2018-09-09 19:36:04,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000350-0000000000000000351
2018-09-09 19:36:04,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000350-0000000000000000351 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 19:36:04,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000351 using no compression
2018-09-09 19:36:04,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000351 of size 4746 bytes saved in 0 seconds.
2018-09-09 19:36:04,637 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 349
2018-09-09 19:36:04,637 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000347, cpktTxId=0000000000000000347)
2018-09-09 19:36:04,666 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 351 to namenode at http://localhost:50070 in 0.026 seconds
2018-09-09 19:36:04,666 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 20:36:05,553 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 20:36:05,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=352&endTxId=353&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 20:36:05,568 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 20:36:05,568 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000352-0000000000000000353_0000000005778213708 size 0 bytes.
2018-09-09 20:36:05,570 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 20:36:05,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000352-0000000000000000353 expecting start txid #352
2018-09-09 20:36:05,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000352-0000000000000000353
2018-09-09 20:36:05,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000352-0000000000000000353 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 20:36:05,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000353 using no compression
2018-09-09 20:36:05,575 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000353 of size 4746 bytes saved in 0 seconds.
2018-09-09 20:36:05,587 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 351
2018-09-09 20:36:05,587 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000349, cpktTxId=0000000000000000349)
2018-09-09 20:36:05,621 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 353 to namenode at http://localhost:50070 in 0.027 seconds
2018-09-09 20:36:05,621 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-09 22:35:59,570 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-09 22:35:59,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=354&endTxId=355&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-09 22:35:59,591 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-09 22:35:59,591 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000354-0000000000000000355_0000000005781814692 size 0 bytes.
2018-09-09 22:35:59,593 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-09 22:35:59,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000354-0000000000000000355 expecting start txid #354
2018-09-09 22:35:59,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000354-0000000000000000355
2018-09-09 22:35:59,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000354-0000000000000000355 of size 42 edits # 2 loaded in 0 seconds
2018-09-09 22:35:59,597 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000355 using no compression
2018-09-09 22:35:59,606 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000355 of size 4746 bytes saved in 0 seconds.
2018-09-09 22:35:59,626 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 353
2018-09-09 22:35:59,627 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000351, cpktTxId=0000000000000000351)
2018-09-09 22:35:59,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 355 to namenode at http://localhost:50070 in 0.05 seconds
2018-09-09 22:35:59,695 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 03:35:33,005 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 03:35:33,007 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=356&endTxId=357&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 03:35:33,026 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 03:35:33,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000356-0000000000000000357_0000000005785416041 size 0 bytes.
2018-09-10 03:35:33,029 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 03:35:33,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000356-0000000000000000357 expecting start txid #356
2018-09-10 03:35:33,030 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000356-0000000000000000357
2018-09-10 03:35:33,030 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000356-0000000000000000357 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 03:35:33,032 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000357 using no compression
2018-09-10 03:35:33,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000357 of size 4746 bytes saved in 0 seconds.
2018-09-10 03:35:33,052 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 355
2018-09-10 03:35:33,052 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000353, cpktTxId=0000000000000000353)
2018-09-10 03:35:33,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 357 to namenode at http://localhost:50070 in 0.04 seconds
2018-09-10 03:35:33,102 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 07:35:12,896 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 07:35:12,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=358&endTxId=359&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 07:35:12,913 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 07:35:12,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000358-0000000000000000359_0000000005789017224 size 0 bytes.
2018-09-10 07:35:12,915 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 07:35:12,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000358-0000000000000000359 expecting start txid #358
2018-09-10 07:35:12,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000358-0000000000000000359
2018-09-10 07:35:12,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000358-0000000000000000359 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 07:35:12,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000359 using no compression
2018-09-10 07:35:12,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000359 of size 4746 bytes saved in 0 seconds.
2018-09-10 07:35:12,949 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 357
2018-09-10 07:35:12,949 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000355, cpktTxId=0000000000000000355)
2018-09-10 07:35:12,989 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 359 to namenode at http://localhost:50070 in 0.032 seconds
2018-09-10 07:35:12,989 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 09:53:18,550 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 09:53:18,551 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=360&endTxId=361&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 09:53:18,564 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 09:53:18,564 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000360-0000000000000000361_0000000005792618289 size 0 bytes.
2018-09-10 09:53:18,566 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 09:53:18,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000360-0000000000000000361 expecting start txid #360
2018-09-10 09:53:18,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000360-0000000000000000361
2018-09-10 09:53:18,567 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000360-0000000000000000361 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 09:53:18,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000361 using no compression
2018-09-10 09:53:18,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000361 of size 4746 bytes saved in 0 seconds.
2018-09-10 09:53:18,584 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 359
2018-09-10 09:53:18,584 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000357, cpktTxId=0000000000000000357)
2018-09-10 09:53:18,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 361 to namenode at http://localhost:50070 in 0.026 seconds
2018-09-10 09:53:18,613 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 13:14:16,847 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 13:14:16,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=362&endTxId=363&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 13:14:16,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 13:14:16,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000362-0000000000000000363_0000000005796219326 size 0 bytes.
2018-09-10 13:14:16,881 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 13:14:16,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000362-0000000000000000363 expecting start txid #362
2018-09-10 13:14:16,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000362-0000000000000000363
2018-09-10 13:14:16,884 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000362-0000000000000000363 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 13:14:16,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000363 using no compression
2018-09-10 13:14:16,902 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000363 of size 4746 bytes saved in 0 seconds.
2018-09-10 13:14:16,916 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 361
2018-09-10 13:14:16,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000359, cpktTxId=0000000000000000359)
2018-09-10 13:14:16,974 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 363 to namenode at http://localhost:50070 in 0.047 seconds
2018-09-10 13:14:16,975 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 15:13:41,316 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 15:13:41,317 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=364&endTxId=365&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 15:13:41,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 15:13:41,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000364-0000000000000000365_0000000005799820343 size 0 bytes.
2018-09-10 15:13:41,336 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 15:13:41,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000364-0000000000000000365 expecting start txid #364
2018-09-10 15:13:41,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000364-0000000000000000365
2018-09-10 15:13:41,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000364-0000000000000000365 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 15:13:41,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000365 using no compression
2018-09-10 15:13:41,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000365 of size 4746 bytes saved in 0 seconds.
2018-09-10 15:13:41,364 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 363
2018-09-10 15:13:41,364 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000361, cpktTxId=0000000000000000361)
2018-09-10 15:13:41,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 365 to namenode at http://localhost:50070 in 0.043 seconds
2018-09-10 15:13:41,418 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 17:50:58,227 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-10 17:50:58,230 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=366&endTxId=367&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 17:50:58,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2018-09-10 17:50:58,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000366-0000000000000000367_0000000005803421419 size 0 bytes.
2018-09-10 17:50:58,246 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-10 17:50:58,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000366-0000000000000000367 expecting start txid #366
2018-09-10 17:50:58,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000366-0000000000000000367
2018-09-10 17:50:58,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000366-0000000000000000367 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 17:50:58,248 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000367 using no compression
2018-09-10 17:50:58,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000367 of size 4746 bytes saved in 0 seconds.
2018-09-10 17:50:58,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 365
2018-09-10 17:50:58,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000363, cpktTxId=0000000000000000363)
2018-09-10 17:50:58,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 367 to namenode at http://localhost:50070 in 0.03 seconds
2018-09-10 17:50:58,305 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4746
2018-09-10 17:55:58,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(java.lang.ExceptionInInitializerError): java.lang.ExceptionInInitializerError
	at java.base/java.time.ZoneRegion.ofId(ZoneRegion.java:120)
	at java.base/java.time.ZoneId.of(ZoneId.java:408)
	at java.base/java.time.ZoneId.of(ZoneId.java:356)
	at java.base/java.time.ZoneId.of(ZoneId.java:312)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:574)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:563)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.time.ZoneId.systemDefault(ZoneId.java:272)
	at java.logging/java.util.logging.SimpleFormatter.format(SimpleFormatter.java:158)
	at java.logging/java.util.logging.StreamHandler.publish(StreamHandler.java:199)
	at java.logging/java.util.logging.ConsoleHandler.publish(ConsoleHandler.java:95)
	at java.logging/java.util.logging.Logger.log(Logger.java:979)
	at java.logging/java.util.logging.Logger.doLog(Logger.java:1006)
	at java.logging/java.util.logging.Logger.log(Logger.java:1117)
	at com.google.common.cache.LocalCache$Segment$1.run(LocalCache.java:2366)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)
	at com.google.common.util.concurrent.ExecutionList$RunnableExecutorPair.execute(ExecutionList.java:149)
	at com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:105)
	at com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:155)
	at com.google.common.cache.LocalCache$Segment.loadAsync(LocalCache.java:2357)
	at com.google.common.cache.LocalCache$Segment.refresh(LocalCache.java:2421)
	at com.google.common.cache.LocalCache$Segment.scheduleRefresh(LocalCache.java:2399)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2218)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3969)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4829)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:229)
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1665)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:91)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1573)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1563)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:2802)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:5113)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getTransactionID(NameNodeRpcServer.java:1200)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.getTransactionId(NamenodeProtocolServerSideTranslatorPB.java:115)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12021)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)
Caused by: java.time.zone.ZoneRulesException: Unable to load TZDB time-zone rules
	at java.base/java.time.zone.TzdbZoneRulesProvider.<init>(TzdbZoneRulesProvider.java:116)
	at java.base/java.time.zone.ZoneRulesProvider$1.run(ZoneRulesProvider.java:164)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.time.zone.ZoneRulesProvider.<clinit>(ZoneRulesProvider.java:150)
	... 45 more
Caused by: java.io.FileNotFoundException: /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/lib/tzdb.dat (No such file or directory)
	at java.base/java.io.FileInputStream.open0(Native Method)
	at java.base/java.io.FileInputStream.open(FileInputStream.java:220)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:158)
	at java.base/java.time.zone.TzdbZoneRulesProvider.<init>(TzdbZoneRulesProvider.java:110)
	... 48 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1481)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-10 17:56:58,774 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(java.lang.NoClassDefFoundError): Could not initialize class java.time.zone.ZoneRulesProvider
	at java.base/java.time.ZoneRegion.ofId(ZoneRegion.java:120)
	at java.base/java.time.ZoneId.of(ZoneId.java:408)
	at java.base/java.time.ZoneId.of(ZoneId.java:356)
	at java.base/java.time.ZoneId.of(ZoneId.java:312)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:574)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:563)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.time.ZoneId.systemDefault(ZoneId.java:272)
	at java.logging/java.util.logging.SimpleFormatter.format(SimpleFormatter.java:158)
	at java.logging/java.util.logging.StreamHandler.publish(StreamHandler.java:199)
	at java.logging/java.util.logging.ConsoleHandler.publish(ConsoleHandler.java:95)
	at java.logging/java.util.logging.Logger.log(Logger.java:979)
	at java.logging/java.util.logging.Logger.doLog(Logger.java:1006)
	at java.logging/java.util.logging.Logger.log(Logger.java:1117)
	at com.google.common.cache.LocalCache$Segment$1.run(LocalCache.java:2366)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)
	at com.google.common.util.concurrent.ExecutionList$RunnableExecutorPair.execute(ExecutionList.java:149)
	at com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:105)
	at com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:155)
	at com.google.common.cache.LocalCache$Segment.loadAsync(LocalCache.java:2357)
	at com.google.common.cache.LocalCache$Segment.refresh(LocalCache.java:2421)
	at com.google.common.cache.LocalCache$Segment.scheduleRefresh(LocalCache.java:2399)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2218)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3969)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4829)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:229)
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1665)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:91)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1573)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1563)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:2802)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:5113)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getTransactionID(NameNodeRpcServer.java:1200)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.getTransactionId(NamenodeProtocolServerSideTranslatorPB.java:115)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12021)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1481)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-10 17:57:58,798 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(java.lang.NoClassDefFoundError): Could not initialize class java.time.zone.ZoneRulesProvider
	at java.base/java.time.ZoneRegion.ofId(ZoneRegion.java:120)
	at java.base/java.time.ZoneId.of(ZoneId.java:408)
	at java.base/java.time.ZoneId.of(ZoneId.java:356)
	at java.base/java.time.ZoneId.of(ZoneId.java:312)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:574)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.util.TimeZone.toZoneId0(TimeZone.java:563)
	at java.base/java.util.TimeZone.toZoneId(TimeZone.java:551)
	at java.base/java.time.ZoneId.systemDefault(ZoneId.java:272)
	at java.logging/java.util.logging.SimpleFormatter.format(SimpleFormatter.java:158)
	at java.logging/java.util.logging.StreamHandler.publish(StreamHandler.java:199)
	at java.logging/java.util.logging.ConsoleHandler.publish(ConsoleHandler.java:95)
	at java.logging/java.util.logging.Logger.log(Logger.java:979)
	at java.logging/java.util.logging.Logger.doLog(Logger.java:1006)
	at java.logging/java.util.logging.Logger.log(Logger.java:1117)
	at com.google.common.cache.LocalCache$Segment$1.run(LocalCache.java:2366)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)
	at com.google.common.util.concurrent.ExecutionList$RunnableExecutorPair.execute(ExecutionList.java:149)
	at com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:105)
	at com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:155)
	at com.google.common.cache.LocalCache$Segment.loadAsync(LocalCache.java:2357)
	at com.google.common.cache.LocalCache$Segment.refresh(LocalCache.java:2421)
	at com.google.common.cache.LocalCache$Segment.scheduleRefresh(LocalCache.java:2399)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2218)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3969)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4829)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:229)
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1665)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:91)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1573)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getPermissionChecker(FSDirectory.java:1563)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:2802)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:5113)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getTransactionID(NameNodeRpcServer.java:1200)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.getTransactionId(NamenodeProtocolServerSideTranslatorPB.java:115)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12021)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1481)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy12.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:127)
	at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)
	at com.sun.proxy.$Proxy13.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:650)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:658)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:455)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-10 17:58:50,254 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-10 17:58:50,263 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at Jasons-MacBook-Pro.local/192.168.1.103
************************************************************/
2018-09-10 18:00:07,155 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = jasons-macbook-pro.local/192.168.1.103
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-10 18:00:07,162 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-10 18:00:07,469 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-10 18:00:07,570 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-10 18:00:07,634 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-10 18:00:07,634 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-10 18:00:07,779 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-10 18:00:07,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 69534@jasons-macbook-pro.local
2018-09-10 18:00:07,806 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-10 18:00:07,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-10 18:00:07,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-10 18:00:07,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-10 18:00:07,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-10 18:00:07,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-10 18:00:07,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 10 18:00:07
2018-09-10 18:00:07,840 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-10 18:00:07,840 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:00:07,841 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-10 18:00:07,841 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-10 18:00:07,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-10 18:00:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-10 18:00:07,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-10 18:00:07,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-10 18:00:07,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-10 18:00:07,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-10 18:00:07,856 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-10 18:00:08,020 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-10 18:00:08,021 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:00:08,021 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-10 18:00:08,021 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-10 18:00:08,021 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-10 18:00:08,021 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-10 18:00:08,021 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-10 18:00:08,027 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-10 18:00:08,027 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:00:08,027 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-10 18:00:08,027 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-10 18:00:08,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-10 18:00:08,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-10 18:00:08,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-10 18:00:08,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-10 18:00:08,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-10 18:00:08,031 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-10 18:00:08,059 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-10 18:00:08,059 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-10 18:00:08,065 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-10 18:00:08,113 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-10 18:00:08,121 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-10 18:00:08,125 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-10 18:00:08,130 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-10 18:00:08,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-10 18:00:08,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-10 18:00:08,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-10 18:00:08,156 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-10 18:00:08,156 INFO org.mortbay.log: jetty-6.1.26
2018-09-10 18:00:08,252 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-10 18:00:08,252 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-10 18:01:08,409 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-10 18:01:08,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=367&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-10 18:01:08,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-10 18:01:08,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2018-09-10 18:01:08,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000367 size 4746 bytes.
2018-09-10 18:01:08,646 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=368&endTxId=368&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 18:01:08,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 204800.00 KB/s
2018-09-10 18:01:08,654 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000368-0000000000000000368_0000000005804031835 size 0 bytes.
2018-09-10 18:01:08,654 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=369&endTxId=374&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 18:01:08,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-10 18:01:08,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000369-0000000000000000374_0000000005804031843 size 0 bytes.
2018-09-10 18:01:08,698 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 62 INodes.
2018-09-10 18:01:08,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-10 18:01:08,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 367 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000367
2018-09-10 18:01:08,727 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-10 18:01:08,735 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2018-09-10 18:01:08,739 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000368-0000000000000000368 expecting start txid #368
2018-09-10 18:01:08,739 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000368-0000000000000000368
2018-09-10 18:01:08,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000368-0000000000000000368 of size 1048576 edits # 1 loaded in 0 seconds
2018-09-10 18:01:08,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000369-0000000000000000374 expecting start txid #369
2018-09-10 18:01:08,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000369-0000000000000000374
2018-09-10 18:01:08,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000369-0000000000000000374 of size 452 edits # 6 loaded in 0 seconds
2018-09-10 18:01:08,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000374 using no compression
2018-09-10 18:01:08,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000374 of size 5033 bytes saved in 0 seconds.
2018-09-10 18:01:08,799 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 367
2018-09-10 18:01:08,799 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000365, cpktTxId=0000000000000000365)
2018-09-10 18:01:08,829 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 374 to namenode at http://localhost:50070 in 0.019 seconds
2018-09-10 18:01:08,829 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5033
2018-09-10 18:39:10,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-10 18:39:11,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-10 18:39:11,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-10 18:39:11,365 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jasons-macbook-pro.local/192.168.1.103
************************************************************/
2018-09-10 18:39:45,144 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = jasons-macbook-pro.local/192.168.1.103
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-10 18:39:45,151 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-10 18:39:45,443 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-10 18:39:45,532 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-10 18:39:45,591 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-10 18:39:45,591 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-10 18:39:45,721 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-10 18:39:45,732 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 71127@jasons-macbook-pro.local
2018-09-10 18:39:45,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-10 18:39:45,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-10 18:39:45,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-10 18:39:45,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-10 18:39:45,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-10 18:39:45,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-10 18:39:45,776 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 10 18:39:45
2018-09-10 18:39:45,777 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-10 18:39:45,777 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:39:45,778 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-10 18:39:45,778 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-10 18:39:45,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-10 18:39:45,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-10 18:39:45,791 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-10 18:39:45,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-10 18:39:45,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-10 18:39:45,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-10 18:39:45,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-10 18:39:45,946 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-10 18:39:45,946 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:39:45,946 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-10 18:39:45,946 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-10 18:39:45,947 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-10 18:39:45,947 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-10 18:39:45,947 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-10 18:39:45,952 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-10 18:39:45,952 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-10 18:39:45,952 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-10 18:39:45,952 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-10 18:39:45,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-10 18:39:45,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-10 18:39:45,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-10 18:39:45,955 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-10 18:39:45,955 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-10 18:39:45,955 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-10 18:39:45,982 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-10 18:39:45,982 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-10 18:39:45,988 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-10 18:39:46,031 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-10 18:39:46,039 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-10 18:39:46,043 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-10 18:39:46,047 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-10 18:39:46,048 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-10 18:39:46,048 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-10 18:39:46,048 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-10 18:39:46,074 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-10 18:39:46,074 INFO org.mortbay.log: jetty-6.1.26
2018-09-10 18:39:46,174 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-10 18:39:46,174 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-10 18:40:46,370 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-10 18:40:46,477 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=374&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-10 18:40:46,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-10 18:40:46,665 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 666.67 KB/s
2018-09-10 18:40:46,666 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000374 size 5033 bytes.
2018-09-10 18:40:46,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=375&endTxId=385&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 18:40:46,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 128000.00 KB/s
2018-09-10 18:40:46,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000375-0000000000000000385_0000000005806409861 size 0 bytes.
2018-09-10 18:40:46,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=386&endTxId=387&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-10 18:40:46,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-10 18:40:46,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000386-0000000000000000387_0000000005806409874 size 0 bytes.
2018-09-10 18:40:46,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2018-09-10 18:40:46,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-10 18:40:46,806 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 374 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000374
2018-09-10 18:40:46,806 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-10 18:40:46,811 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2018-09-10 18:40:46,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000375-0000000000000000385 expecting start txid #375
2018-09-10 18:40:46,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000375-0000000000000000385
2018-09-10 18:40:46,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000375-0000000000000000385 of size 1048576 edits # 11 loaded in 0 seconds
2018-09-10 18:40:46,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000386-0000000000000000387 expecting start txid #386
2018-09-10 18:40:46,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000386-0000000000000000387
2018-09-10 18:40:46,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000386-0000000000000000387 of size 42 edits # 2 loaded in 0 seconds
2018-09-10 18:40:46,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000387 using no compression
2018-09-10 18:40:46,898 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000387 of size 4866 bytes saved in 0 seconds.
2018-09-10 18:40:46,905 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 374
2018-09-10 18:40:46,905 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000367, cpktTxId=0000000000000000367)
2018-09-10 18:40:46,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 387 to namenode at http://localhost:50070 in 0.037 seconds
2018-09-10 18:40:46,955 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4866
2018-09-10 18:49:08,196 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-10 18:49:08,201 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jasons-macbook-pro.local/192.168.1.103
************************************************************/
2018-09-13 13:04:36,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = jasons-macbook-pro.local/10.169.0.233
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-13 13:04:36,794 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-13 13:04:37,084 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-13 13:04:37,174 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-13 13:04:37,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-13 13:04:37,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-13 13:04:37,413 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-13 13:04:37,426 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 7437@jasons-macbook-pro.local
2018-09-13 13:04:37,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-13 13:04:37,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-13 13:04:37,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-13 13:04:37,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-13 13:04:37,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-13 13:04:37,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-13 13:04:37,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 13 13:04:37
2018-09-13 13:04:37,465 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-13 13:04:37,465 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:04:37,465 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-13 13:04:37,466 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-13 13:04:37,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-13 13:04:37,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-13 13:04:37,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-13 13:04:37,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-13 13:04:37,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-13 13:04:37,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-13 13:04:37,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-13 13:04:37,630 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-13 13:04:37,630 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:04:37,630 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-13 13:04:37,630 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-13 13:04:37,631 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-13 13:04:37,631 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-13 13:04:37,631 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-13 13:04:37,636 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-13 13:04:37,636 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:04:37,636 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-13 13:04:37,636 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-13 13:04:37,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-13 13:04:37,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-13 13:04:37,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-13 13:04:37,640 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-13 13:04:37,640 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-13 13:04:37,640 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-13 13:04:37,649 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-13 13:04:37,649 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-13 13:04:37,654 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-13 13:04:37,716 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-13 13:04:37,723 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-13 13:04:37,727 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-13 13:04:37,731 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-13 13:04:37,732 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-13 13:04:37,732 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-13 13:04:37,732 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-13 13:04:37,757 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-13 13:04:37,757 INFO org.mortbay.log: jetty-6.1.26
2018-09-13 13:04:37,848 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-13 13:04:37,848 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-13 13:05:38,037 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-13 13:05:38,127 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=490&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-13 13:05:38,150 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-13 13:05:38,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1250.00 KB/s
2018-09-13 13:05:38,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000490 size 5417 bytes.
2018-09-13 13:05:38,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=491&endTxId=492&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 13:05:38,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 13:05:38,280 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000491-0000000000000000492_0000000000052878292 size 0 bytes.
2018-09-13 13:05:38,321 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 70 INodes.
2018-09-13 13:05:38,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-13 13:05:38,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 490 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000490
2018-09-13 13:05:38,353 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-13 13:05:38,359 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 13:05:38,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000491-0000000000000000492 expecting start txid #491
2018-09-13 13:05:38,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000491-0000000000000000492
2018-09-13 13:05:38,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000491-0000000000000000492 of size 42 edits # 2 loaded in 0 seconds
2018-09-13 13:05:38,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000492 using no compression
2018-09-13 13:05:38,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000492 of size 5417 bytes saved in 0 seconds.
2018-09-13 13:05:38,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jason/dfs/namesecondary
2018-09-13 13:05:38,414 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jason/dfs/namesecondary
2018-09-13 13:05:38,432 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 492 to namenode at http://localhost:50070 in 0.017 seconds
2018-09-13 13:05:38,432 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5417
2018-09-13 13:06:04,610 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-13 13:06:04,612 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jasons-macbook-pro.local/10.169.0.233
************************************************************/
2018-09-13 13:14:24,391 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = jasons-macbook-pro.local/10.169.0.233
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-13 13:14:24,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-13 13:14:24,701 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-13 13:14:24,793 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-13 13:14:24,853 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-13 13:14:24,853 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-13 13:14:24,967 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-13 13:14:24,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 8387@jasons-macbook-pro.local
2018-09-13 13:14:24,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-13 13:14:24,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-13 13:14:24,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-13 13:14:25,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-13 13:14:25,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-13 13:14:25,023 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-13 13:14:25,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 13 13:14:25
2018-09-13 13:14:25,025 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-13 13:14:25,025 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:14:25,026 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-13 13:14:25,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-13 13:14:25,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-13 13:14:25,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-13 13:14:25,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-13 13:14:25,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-13 13:14:25,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-13 13:14:25,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-13 13:14:25,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-13 13:14:25,190 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-13 13:14:25,190 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:14:25,190 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-13 13:14:25,190 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-13 13:14:25,191 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-13 13:14:25,191 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-13 13:14:25,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-13 13:14:25,196 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-13 13:14:25,196 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 13:14:25,196 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-13 13:14:25,196 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-13 13:14:25,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-13 13:14:25,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-13 13:14:25,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-13 13:14:25,200 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-13 13:14:25,200 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-13 13:14:25,200 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-13 13:14:25,207 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-13 13:14:25,207 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-13 13:14:25,233 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-13 13:14:25,275 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-13 13:14:25,282 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-13 13:14:25,286 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-13 13:14:25,291 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-13 13:14:25,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-13 13:14:25,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-13 13:14:25,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-13 13:14:25,314 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-13 13:14:25,314 INFO org.mortbay.log: jetty-6.1.26
2018-09-13 13:14:25,410 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-13 13:14:25,411 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-13 13:15:25,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-13 13:15:25,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=492&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-13 13:15:25,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-13 13:15:25,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2018-09-13 13:15:25,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000492 size 5417 bytes.
2018-09-13 13:15:25,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=493&endTxId=493&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 13:15:25,806 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 146285.71 KB/s
2018-09-13 13:15:25,807 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000493-0000000000000000493_0000000000053465810 size 0 bytes.
2018-09-13 13:15:25,807 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=494&endTxId=495&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 13:15:25,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 13:15:25,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000494-0000000000000000495_0000000000053465820 size 0 bytes.
2018-09-13 13:15:25,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 70 INodes.
2018-09-13 13:15:25,879 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-13 13:15:25,879 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 492 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000492
2018-09-13 13:15:25,879 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-13 13:15:25,882 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2018-09-13 13:15:25,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000493-0000000000000000493 expecting start txid #493
2018-09-13 13:15:25,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000493-0000000000000000493
2018-09-13 13:15:25,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000493-0000000000000000493 of size 1048576 edits # 1 loaded in 0 seconds
2018-09-13 13:15:25,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000494-0000000000000000495 expecting start txid #494
2018-09-13 13:15:25,898 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000494-0000000000000000495
2018-09-13 13:15:25,898 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000494-0000000000000000495 of size 42 edits # 2 loaded in 0 seconds
2018-09-13 13:15:25,901 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000495 using no compression
2018-09-13 13:15:25,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000495 of size 5417 bytes saved in 0 seconds.
2018-09-13 13:15:25,933 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 492
2018-09-13 13:15:25,933 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000490, cpktTxId=0000000000000000490)
2018-09-13 13:15:25,956 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 495 to namenode at http://localhost:50070 in 0.018 seconds
2018-09-13 13:15:25,957 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5417
2018-09-13 14:15:26,687 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 14:15:26,688 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=496&endTxId=497&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 14:15:26,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 14:15:26,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000496-0000000000000000497_0000000000057066694 size 0 bytes.
2018-09-13 14:15:26,692 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 14:15:26,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000496-0000000000000000497 expecting start txid #496
2018-09-13 14:15:26,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000496-0000000000000000497
2018-09-13 14:15:26,693 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000496-0000000000000000497 of size 42 edits # 2 loaded in 0 seconds
2018-09-13 14:15:26,693 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000497 using no compression
2018-09-13 14:15:26,698 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000497 of size 5417 bytes saved in 0 seconds.
2018-09-13 14:15:26,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 495
2018-09-13 14:15:26,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000492, cpktTxId=0000000000000000492)
2018-09-13 14:15:26,711 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 497 to namenode at http://localhost:50070 in 0.01 seconds
2018-09-13 14:15:26,711 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5417
2018-09-13 14:30:08,610 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-13 14:30:08,612 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at jasons-macbook-pro.local/10.169.0.233
************************************************************/
2018-09-13 17:46:56,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   user = jason
STARTUP_MSG:   host = jasons-macbook-pro.local/192.168.1.103
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/jason/hadoop-2.8.1/etc/hadoop:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/jason/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar:/Users/jason/hadoop-2.8.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-13 17:46:56,103 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-13 17:46:56,396 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-13 17:46:56,485 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-13 17:46:56,544 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-13 17:46:56,544 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-13 17:46:56,658 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
2018-09-13 17:46:56,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jason/dfs/namesecondary/in_use.lock acquired by nodename 12247@jasons-macbook-pro.local
2018-09-13 17:46:56,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-13 17:46:56,690 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-13 17:46:56,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-13 17:46:56,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-13 17:46:56,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-13 17:46:56,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-13 17:46:56,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 13 17:46:56
2018-09-13 17:46:56,723 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-13 17:46:56,723 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 17:46:56,724 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-13 17:46:56,724 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-13 17:46:56,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-13 17:46:56,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-13 17:46:56,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jason (auth:SIMPLE)
2018-09-13 17:46:56,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-13 17:46:56,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-13 17:46:56,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-13 17:46:56,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-13 17:46:56,886 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-13 17:46:56,886 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 17:46:56,887 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-13 17:46:56,887 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-13 17:46:56,887 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-13 17:46:56,887 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-13 17:46:56,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-13 17:46:56,892 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-13 17:46:56,892 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-13 17:46:56,892 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-13 17:46:56,892 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-13 17:46:56,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-13 17:46:56,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-13 17:46:56,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-13 17:46:56,896 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-13 17:46:56,896 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-13 17:46:56,896 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-13 17:46:56,903 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-13 17:46:56,903 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-13 17:46:56,928 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-13 17:46:56,971 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-13 17:46:56,978 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-13 17:46:56,982 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-13 17:46:56,986 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-13 17:46:56,988 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-13 17:46:56,988 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-13 17:46:56,988 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-13 17:46:57,011 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-13 17:46:57,011 INFO org.mortbay.log: jetty-6.1.26
2018-09-13 17:46:57,105 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-13 17:46:57,106 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-13 17:47:57,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-13 17:47:57,349 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=498&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e&bootstrapstandby=false
2018-09-13 17:47:57,369 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-13 17:47:57,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2018-09-13 17:47:57,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000498 size 5417 bytes.
2018-09-13 17:47:57,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=499&endTxId=500&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 17:47:57,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 17:47:57,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000499-0000000000000000500_0000000000060396486 size 0 bytes.
2018-09-13 17:47:57,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 70 INodes.
2018-09-13 17:47:57,564 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-13 17:47:57,564 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 498 from /tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000498
2018-09-13 17:47:57,564 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-13 17:47:57,568 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 17:47:57,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000499-0000000000000000500 expecting start txid #499
2018-09-13 17:47:57,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000499-0000000000000000500
2018-09-13 17:47:57,582 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000499-0000000000000000500 of size 42 edits # 2 loaded in 0 seconds
2018-09-13 17:47:57,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000500 using no compression
2018-09-13 17:47:57,615 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000500 of size 5417 bytes saved in 0 seconds.
2018-09-13 17:47:57,619 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 498
2018-09-13 17:47:57,619 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000495, cpktTxId=0000000000000000495)
2018-09-13 17:47:57,619 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000497, cpktTxId=0000000000000000497)
2018-09-13 17:47:57,640 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 500 to namenode at http://localhost:50070 in 0.015 seconds
2018-09-13 17:47:57,640 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5417
2018-09-13 18:47:58,301 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 18:47:58,302 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=501&endTxId=514&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 18:47:58,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2018-09-13 18:47:58,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000501-0000000000000000514_0000000000063997290 size 0 bytes.
2018-09-13 18:47:58,306 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 18:47:58,306 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000501-0000000000000000514 expecting start txid #501
2018-09-13 18:47:58,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000501-0000000000000000514
2018-09-13 18:47:58,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000501-0000000000000000514 of size 1103 edits # 14 loaded in 0 seconds
2018-09-13 18:47:58,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000514 using no compression
2018-09-13 18:47:58,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000514 of size 5739 bytes saved in 0 seconds.
2018-09-13 18:47:58,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 500
2018-09-13 18:47:58,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000498, cpktTxId=0000000000000000498)
2018-09-13 18:47:58,349 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 514 to namenode at http://localhost:50070 in 0.008 seconds
2018-09-13 18:47:58,349 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5739
2018-09-13 19:47:59,691 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 19:47:59,691 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=515&endTxId=517&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 19:47:59,694 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 19:47:59,694 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000515-0000000000000000517_0000000000067597897 size 0 bytes.
2018-09-13 19:47:59,695 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 19:47:59,695 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000515-0000000000000000517 expecting start txid #515
2018-09-13 19:47:59,695 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000515-0000000000000000517
2018-09-13 19:47:59,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000515-0000000000000000517 of size 103 edits # 3 loaded in 0 seconds
2018-09-13 19:47:59,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000517 using no compression
2018-09-13 19:47:59,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000517 of size 5739 bytes saved in 0 seconds.
2018-09-13 19:47:59,702 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 514
2018-09-13 19:47:59,702 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000500, cpktTxId=0000000000000000500)
2018-09-13 19:47:59,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 517 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-13 19:47:59,709 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5739
2018-09-13 20:48:00,286 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 20:48:00,287 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=518&endTxId=520&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000518-0000000000000000520_0000000000071198489 size 0 bytes.
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000518-0000000000000000520 expecting start txid #518
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000518-0000000000000000520
2018-09-13 20:48:00,291 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000518-0000000000000000520 of size 103 edits # 3 loaded in 0 seconds
2018-09-13 20:48:00,292 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000520 using no compression
2018-09-13 20:48:00,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000520 of size 5739 bytes saved in 0 seconds.
2018-09-13 20:48:00,297 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 517
2018-09-13 20:48:00,298 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000514, cpktTxId=0000000000000000514)
2018-09-13 20:48:00,307 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 520 to namenode at http://localhost:50070 in 0.007 seconds
2018-09-13 20:48:00,307 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5739
2018-09-13 22:02:15,914 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 22:02:15,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=521&endTxId=522&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 22:02:15,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-13 22:02:15,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000521-0000000000000000522_0000000000074799156 size 0 bytes.
2018-09-13 22:02:15,917 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 22:02:15,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000521-0000000000000000522 expecting start txid #521
2018-09-13 22:02:15,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000521-0000000000000000522
2018-09-13 22:02:15,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000521-0000000000000000522 of size 42 edits # 2 loaded in 0 seconds
2018-09-13 22:02:15,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000522 using no compression
2018-09-13 22:02:15,921 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000522 of size 5739 bytes saved in 0 seconds.
2018-09-13 22:02:15,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 520
2018-09-13 22:02:15,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000517, cpktTxId=0000000000000000517)
2018-09-13 22:02:15,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 522 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-13 22:02:15,930 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5739
2018-09-13 23:02:16,538 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-13 23:02:16,539 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=523&endTxId=815&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-13 23:02:16,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 48000.00 KB/s
2018-09-13 23:02:16,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000523-0000000000000000815_0000000000078399774 size 0 bytes.
2018-09-13 23:02:16,543 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-13 23:02:16,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000523-0000000000000000815 expecting start txid #523
2018-09-13 23:02:16,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000523-0000000000000000815
2018-09-13 23:02:16,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000523-0000000000000000815 of size 49875 edits # 293 loaded in 0 seconds
2018-09-13 23:02:16,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000815 using no compression
2018-09-13 23:02:16,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000815 of size 10180 bytes saved in 0 seconds.
2018-09-13 23:02:16,579 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 522
2018-09-13 23:02:16,579 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000520, cpktTxId=0000000000000000520)
2018-09-13 23:02:16,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 815 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-13 23:02:16,586 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-14 11:05:08,105 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-14 11:05:08,106 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=816&endTxId=817&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-14 11:05:08,109 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-14 11:05:08,109 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000816-0000000000000000817_0000000000082000457 size 0 bytes.
2018-09-14 11:05:08,109 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-14 11:05:08,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000816-0000000000000000817 expecting start txid #816
2018-09-14 11:05:08,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000816-0000000000000000817
2018-09-14 11:05:08,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000816-0000000000000000817 of size 42 edits # 2 loaded in 0 seconds
2018-09-14 11:05:08,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000817 using no compression
2018-09-14 11:05:08,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000817 of size 10180 bytes saved in 0 seconds.
2018-09-14 11:05:08,115 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 815
2018-09-14 11:05:08,115 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000522, cpktTxId=0000000000000000522)
2018-09-14 11:05:08,121 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 817 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-14 11:05:08,121 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-14 17:04:37,700 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-14 17:04:37,701 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=818&endTxId=819&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-14 17:04:37,703 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-14 17:04:37,703 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000818-0000000000000000819_0000000000085601130 size 0 bytes.
2018-09-14 17:04:37,704 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-14 17:04:37,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000818-0000000000000000819 expecting start txid #818
2018-09-14 17:04:37,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000818-0000000000000000819
2018-09-14 17:04:37,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000818-0000000000000000819 of size 42 edits # 2 loaded in 0 seconds
2018-09-14 17:04:37,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000819 using no compression
2018-09-14 17:04:37,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000819 of size 10180 bytes saved in 0 seconds.
2018-09-14 17:04:37,709 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 817
2018-09-14 17:04:37,709 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000815, cpktTxId=0000000000000000815)
2018-09-14 17:04:37,716 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 819 to namenode at http://localhost:50070 in 0.004 seconds
2018-09-14 17:04:37,716 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-14 18:04:39,524 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-14 18:04:39,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=820&endTxId=821&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-14 18:04:39,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-14 18:04:39,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000820-0000000000000000821_0000000000089201729 size 0 bytes.
2018-09-14 18:04:39,528 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-14 18:04:39,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000820-0000000000000000821 expecting start txid #820
2018-09-14 18:04:39,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000820-0000000000000000821
2018-09-14 18:04:39,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000820-0000000000000000821 of size 42 edits # 2 loaded in 0 seconds
2018-09-14 18:04:39,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000821 using no compression
2018-09-14 18:04:39,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000821 of size 10180 bytes saved in 0 seconds.
2018-09-14 18:04:39,533 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 819
2018-09-14 18:04:39,533 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000817, cpktTxId=0000000000000000817)
2018-09-14 18:04:39,540 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 821 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-14 18:04:39,540 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-14 19:04:40,083 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-14 19:04:40,084 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=822&endTxId=823&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000822-0000000000000000823_0000000000092802278 size 0 bytes.
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000822-0000000000000000823 expecting start txid #822
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000822-0000000000000000823
2018-09-14 19:04:40,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000822-0000000000000000823 of size 42 edits # 2 loaded in 0 seconds
2018-09-14 19:04:40,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000823 using no compression
2018-09-14 19:04:40,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000823 of size 10180 bytes saved in 0 seconds.
2018-09-14 19:04:40,094 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 821
2018-09-14 19:04:40,094 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000819, cpktTxId=0000000000000000819)
2018-09-14 19:04:40,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 823 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-14 19:04:40,102 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-14 20:04:40,726 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-14 20:04:40,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=824&endTxId=825&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-14 20:04:40,730 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-14 20:04:40,730 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000824-0000000000000000825_0000000000096402910 size 0 bytes.
2018-09-14 20:04:40,730 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-14 20:04:40,730 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000824-0000000000000000825 expecting start txid #824
2018-09-14 20:04:40,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000824-0000000000000000825
2018-09-14 20:04:40,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000824-0000000000000000825 of size 42 edits # 2 loaded in 0 seconds
2018-09-14 20:04:40,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000825 using no compression
2018-09-14 20:04:40,734 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000825 of size 10180 bytes saved in 0 seconds.
2018-09-14 20:04:40,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 823
2018-09-14 20:04:40,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000821, cpktTxId=0000000000000000821)
2018-09-14 20:04:40,742 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 825 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-14 20:04:40,743 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-15 20:18:02,814 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-15 20:18:02,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=826&endTxId=827&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-15 20:18:02,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-15 20:18:02,819 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000826-0000000000000000827_0000000000100003711 size 0 bytes.
2018-09-15 20:18:02,819 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-15 20:18:02,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000826-0000000000000000827 expecting start txid #826
2018-09-15 20:18:02,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000826-0000000000000000827
2018-09-15 20:18:02,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000826-0000000000000000827 of size 42 edits # 2 loaded in 0 seconds
2018-09-15 20:18:02,820 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000827 using no compression
2018-09-15 20:18:02,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000827 of size 10180 bytes saved in 0 seconds.
2018-09-15 20:18:02,825 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 825
2018-09-15 20:18:02,825 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000823, cpktTxId=0000000000000000823)
2018-09-15 20:18:02,833 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 827 to namenode at http://localhost:50070 in 0.007 seconds
2018-09-15 20:18:02,833 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-17 11:40:40,953 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-17 11:40:40,954 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=828&endTxId=829&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-17 11:40:40,957 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-17 11:40:40,957 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000828-0000000000000000829_0000000000103605363 size 0 bytes.
2018-09-17 11:40:40,957 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-17 11:40:40,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000828-0000000000000000829 expecting start txid #828
2018-09-17 11:40:40,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000828-0000000000000000829
2018-09-17 11:40:40,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000828-0000000000000000829 of size 42 edits # 2 loaded in 0 seconds
2018-09-17 11:40:40,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000829 using no compression
2018-09-17 11:40:40,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000829 of size 10180 bytes saved in 0 seconds.
2018-09-17 11:40:40,965 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 827
2018-09-17 11:40:40,965 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000825, cpktTxId=0000000000000000825)
2018-09-17 11:40:40,973 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 829 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-17 11:40:40,974 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-18 09:57:01,455 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 09:57:01,458 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=830&endTxId=832&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 09:57:01,466 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-18 09:57:01,466 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000830-0000000000000000832_0000000000107223709 size 0 bytes.
2018-09-18 09:57:01,467 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 09:57:01,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000830-0000000000000000832 expecting start txid #830
2018-09-18 09:57:01,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000830-0000000000000000832
2018-09-18 09:57:01,470 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000830-0000000000000000832 of size 103 edits # 3 loaded in 0 seconds
2018-09-18 09:57:01,471 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000832 using no compression
2018-09-18 09:57:01,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000832 of size 10180 bytes saved in 0 seconds.
2018-09-18 09:57:01,479 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 829
2018-09-18 09:57:01,479 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000827, cpktTxId=0000000000000000827)
2018-09-18 09:57:01,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 832 to namenode at http://localhost:50070 in 0.007 seconds
2018-09-18 09:57:01,489 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10180
2018-09-18 13:22:36,639 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 13:22:36,640 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=833&endTxId=955&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 13:22:36,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 14000.00 KB/s
2018-09-18 13:22:36,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000833-0000000000000000955_0000000000110824488 size 0 bytes.
2018-09-18 13:22:36,644 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 13:22:36,644 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000833-0000000000000000955 expecting start txid #833
2018-09-18 13:22:36,644 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000833-0000000000000000955
2018-09-18 13:22:36,648 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0001/job.jar
2018-09-18 13:22:36,649 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0001/job.split
2018-09-18 13:22:36,663 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0002/job.jar
2018-09-18 13:22:36,663 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0002/job.split
2018-09-18 13:22:36,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000833-0000000000000000955 of size 14660 edits # 123 loaded in 0 seconds
2018-09-18 13:22:36,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000955 using no compression
2018-09-18 13:22:36,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000955 of size 11248 bytes saved in 0 seconds.
2018-09-18 13:22:36,669 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 832
2018-09-18 13:22:36,669 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000829, cpktTxId=0000000000000000829)
2018-09-18 13:22:36,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 955 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-18 13:22:36,677 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11248
2018-09-18 14:59:32,857 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 14:59:32,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=956&endTxId=985&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 14:59:32,861 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2018-09-18 14:59:32,861 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000956-0000000000000000985_0000000000114425192 size 0 bytes.
2018-09-18 14:59:32,862 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 14:59:32,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000956-0000000000000000985 expecting start txid #956
2018-09-18 14:59:32,863 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000956-0000000000000000985
2018-09-18 14:59:32,864 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0003/job.jar
2018-09-18 14:59:32,864 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0003/job.split
2018-09-18 14:59:32,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000956-0000000000000000985 of size 3054 edits # 30 loaded in 0 seconds
2018-09-18 14:59:32,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000985 using no compression
2018-09-18 14:59:32,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000000985 of size 11609 bytes saved in 0 seconds.
2018-09-18 14:59:32,870 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 955
2018-09-18 14:59:32,870 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000832, cpktTxId=0000000000000000832)
2018-09-18 14:59:32,877 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 985 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-18 14:59:32,877 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11609
2018-09-18 20:33:54,312 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 20:33:54,315 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=986&endTxId=1069&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 20:33:54,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 10000.00 KB/s
2018-09-18 20:33:54,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000986-0000000000000001069_0000000000118045684 size 0 bytes.
2018-09-18 20:33:54,334 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 20:33:54,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000986-0000000000000001069 expecting start txid #986
2018-09-18 20:33:54,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000986-0000000000000001069
2018-09-18 20:33:54,342 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0004/job.jar
2018-09-18 20:33:54,342 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0004/job.split
2018-09-18 20:33:54,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000000986-0000000000000001069 of size 10616 edits # 84 loaded in 0 seconds
2018-09-18 20:33:54,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001069 using no compression
2018-09-18 20:33:54,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001069 of size 12156 bytes saved in 0 seconds.
2018-09-18 20:33:54,361 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 985
2018-09-18 20:33:54,361 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000955, cpktTxId=0000000000000000955)
2018-09-18 20:33:54,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1069 to namenode at http://localhost:50070 in 0.01 seconds
2018-09-18 20:33:54,376 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12156
2018-09-18 21:33:55,115 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 21:33:55,116 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1070&endTxId=1071&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 21:33:55,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-18 21:33:55,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001070-0000000000000001071_0000000000121646476 size 0 bytes.
2018-09-18 21:33:55,119 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 21:33:55,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001070-0000000000000001071 expecting start txid #1070
2018-09-18 21:33:55,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001070-0000000000000001071
2018-09-18 21:33:55,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001070-0000000000000001071 of size 42 edits # 2 loaded in 0 seconds
2018-09-18 21:33:55,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001071 using no compression
2018-09-18 21:33:55,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001071 of size 12156 bytes saved in 0 seconds.
2018-09-18 21:33:55,123 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1069
2018-09-18 21:33:55,124 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000000985, cpktTxId=0000000000000000985)
2018-09-18 21:33:55,132 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1071 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-18 21:33:55,132 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12156
2018-09-18 23:04:22,806 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-18 23:04:22,807 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1072&endTxId=1074&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001072-0000000000000001074_0000000000125247174 size 0 bytes.
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001072-0000000000000001074 expecting start txid #1072
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001072-0000000000000001074
2018-09-18 23:04:22,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001072-0000000000000001074 of size 108 edits # 3 loaded in 0 seconds
2018-09-18 23:04:22,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001074 using no compression
2018-09-18 23:04:22,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001074 of size 12156 bytes saved in 0 seconds.
2018-09-18 23:04:22,815 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1071
2018-09-18 23:04:22,815 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001069, cpktTxId=0000000000000001069)
2018-09-18 23:04:22,859 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1074 to namenode at http://localhost:50070 in 0.041 seconds
2018-09-18 23:04:22,859 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12156
2018-09-19 11:54:49,525 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 11:54:49,526 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1075&endTxId=1231&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 11:54:49,530 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 21000.00 KB/s
2018-09-19 11:54:49,530 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001075-0000000000000001231_0000000000128851134 size 0 bytes.
2018-09-19 11:54:49,531 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 11:54:49,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001075-0000000000000001231 expecting start txid #1075
2018-09-19 11:54:49,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001075-0000000000000001231
2018-09-19 11:54:49,538 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0005/job.jar
2018-09-19 11:54:49,538 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0005/job.split
2018-09-19 11:54:49,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001075-0000000000000001231 of size 22420 edits # 157 loaded in 0 seconds
2018-09-19 11:54:49,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001231 using no compression
2018-09-19 11:54:49,546 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001231 of size 13622 bytes saved in 0 seconds.
2018-09-19 11:54:49,547 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1074
2018-09-19 11:54:49,547 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001071, cpktTxId=0000000000000001071)
2018-09-19 11:54:49,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1231 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-19 11:54:49,555 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13622
2018-09-19 12:54:50,184 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 12:54:50,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1232&endTxId=1389&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 12:54:50,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 21000.00 KB/s
2018-09-19 12:54:50,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001232-0000000000000001389_0000000000132451783 size 0 bytes.
2018-09-19 12:54:50,188 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 12:54:50,188 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001232-0000000000000001389 expecting start txid #1232
2018-09-19 12:54:50,188 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001232-0000000000000001389
2018-09-19 12:54:50,194 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0006/job.jar
2018-09-19 12:54:50,195 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/jason/.staging/job_1536878829533_0006/job.split
2018-09-19 12:54:50,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001232-0000000000000001389 of size 22182 edits # 158 loaded in 0 seconds
2018-09-19 12:54:50,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001389 using no compression
2018-09-19 12:54:50,200 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001389 of size 11590 bytes saved in 0 seconds.
2018-09-19 12:54:50,202 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1231
2018-09-19 12:54:50,202 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001074, cpktTxId=0000000000000001074)
2018-09-19 12:54:50,210 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1389 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-19 12:54:50,210 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11590
2018-09-19 13:54:50,847 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 13:54:50,847 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1390&endTxId=1403&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 13:54:50,850 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2018-09-19 13:54:50,850 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001390-0000000000000001403_0000000000136052435 size 0 bytes.
2018-09-19 13:54:50,851 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 13:54:50,851 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001390-0000000000000001403 expecting start txid #1390
2018-09-19 13:54:50,851 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001390-0000000000000001403
2018-09-19 13:54:50,851 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001390-0000000000000001403 of size 1182 edits # 14 loaded in 0 seconds
2018-09-19 13:54:50,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001403 using no compression
2018-09-19 13:54:50,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001403 of size 11590 bytes saved in 0 seconds.
2018-09-19 13:54:50,855 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1389
2018-09-19 13:54:50,855 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001231, cpktTxId=0000000000000001231)
2018-09-19 13:54:50,862 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1403 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-19 13:54:50,862 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11590
2018-09-19 16:03:04,364 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 16:03:04,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1404&endTxId=1634&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 16:03:04,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 31000.00 KB/s
2018-09-19 16:03:04,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001404-0000000000000001634_0000000000139653025 size 0 bytes.
2018-09-19 16:03:04,369 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 16:03:04,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001404-0000000000000001634 expecting start txid #1404
2018-09-19 16:03:04,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001404-0000000000000001634
2018-09-19 16:03:04,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001404-0000000000000001634 of size 31975 edits # 231 loaded in 0 seconds
2018-09-19 16:03:04,382 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001634 using no compression
2018-09-19 16:03:04,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001634 of size 13665 bytes saved in 0 seconds.
2018-09-19 16:03:04,387 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1403
2018-09-19 16:03:04,388 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001389, cpktTxId=0000000000000001389)
2018-09-19 16:03:04,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1634 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-19 16:03:04,394 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13665
2018-09-19 17:03:05,149 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 17:03:05,150 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1635&endTxId=1636&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 17:03:05,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-19 17:03:05,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001635-0000000000000001636_0000000000143253800 size 0 bytes.
2018-09-19 17:03:05,154 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 17:03:05,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001635-0000000000000001636 expecting start txid #1635
2018-09-19 17:03:05,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001635-0000000000000001636
2018-09-19 17:03:05,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001635-0000000000000001636 of size 42 edits # 2 loaded in 0 seconds
2018-09-19 17:03:05,155 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001636 using no compression
2018-09-19 17:03:05,159 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001636 of size 13665 bytes saved in 0 seconds.
2018-09-19 17:03:05,160 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1634
2018-09-19 17:03:05,160 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001403, cpktTxId=0000000000000001403)
2018-09-19 17:03:05,167 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1636 to namenode at http://localhost:50070 in 0.005 seconds
2018-09-19 17:03:05,168 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13665
2018-09-19 19:07:01,414 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 19:07:01,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1637&endTxId=1639&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001637-0000000000000001639_0000000000146854467 size 0 bytes.
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001637-0000000000000001639 expecting start txid #1637
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001637-0000000000000001639
2018-09-19 19:07:01,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001637-0000000000000001639 of size 143 edits # 3 loaded in 0 seconds
2018-09-19 19:07:01,418 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001639 using no compression
2018-09-19 19:07:01,420 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001639 of size 13498 bytes saved in 0 seconds.
2018-09-19 19:07:01,422 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1636
2018-09-19 19:07:01,422 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001634, cpktTxId=0000000000000001634)
2018-09-19 19:07:01,433 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1639 to namenode at http://localhost:50070 in 0.009 seconds
2018-09-19 19:07:01,433 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
2018-09-19 20:07:02,030 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 20:07:02,031 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1640&endTxId=1641&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 20:07:02,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-19 20:07:02,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001640-0000000000000001641_0000000000150455075 size 0 bytes.
2018-09-19 20:07:02,036 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 20:07:02,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001640-0000000000000001641 expecting start txid #1640
2018-09-19 20:07:02,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001640-0000000000000001641
2018-09-19 20:07:02,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001640-0000000000000001641 of size 42 edits # 2 loaded in 0 seconds
2018-09-19 20:07:02,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001641 using no compression
2018-09-19 20:07:02,041 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001641 of size 13498 bytes saved in 0 seconds.
2018-09-19 20:07:02,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1639
2018-09-19 20:07:02,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001636, cpktTxId=0000000000000001636)
2018-09-19 20:07:02,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1641 to namenode at http://localhost:50070 in 0.008 seconds
2018-09-19 20:07:02,057 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
2018-09-19 21:07:42,070 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 21:07:42,071 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1642&endTxId=1643&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 21:07:42,074 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-19 21:07:42,074 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001642-0000000000000001643_0000000000154055804 size 0 bytes.
2018-09-19 21:07:42,074 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 21:07:42,075 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001642-0000000000000001643 expecting start txid #1642
2018-09-19 21:07:42,075 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001642-0000000000000001643
2018-09-19 21:07:42,075 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001642-0000000000000001643 of size 42 edits # 2 loaded in 0 seconds
2018-09-19 21:07:42,076 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001643 using no compression
2018-09-19 21:07:42,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001643 of size 13498 bytes saved in 0 seconds.
2018-09-19 21:07:42,081 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1641
2018-09-19 21:07:42,081 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001639, cpktTxId=0000000000000001639)
2018-09-19 21:07:42,100 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1643 to namenode at http://localhost:50070 in 0.009 seconds
2018-09-19 21:07:42,100 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
2018-09-19 22:07:42,792 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-19 22:07:42,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1644&endTxId=1645&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-19 22:07:42,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-19 22:07:42,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001644-0000000000000001645_0000000000157656518 size 0 bytes.
2018-09-19 22:07:42,796 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-19 22:07:42,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001644-0000000000000001645 expecting start txid #1644
2018-09-19 22:07:42,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001644-0000000000000001645
2018-09-19 22:07:42,797 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001644-0000000000000001645 of size 42 edits # 2 loaded in 0 seconds
2018-09-19 22:07:42,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001645 using no compression
2018-09-19 22:07:42,800 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001645 of size 13498 bytes saved in 0 seconds.
2018-09-19 22:07:42,802 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1643
2018-09-19 22:07:42,802 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001641, cpktTxId=0000000000000001641)
2018-09-19 22:07:42,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1645 to namenode at http://localhost:50070 in 0.007 seconds
2018-09-19 22:07:42,812 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
2018-09-20 11:21:09,496 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-20 11:21:09,499 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1646&endTxId=1647&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-20 11:21:09,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-20 11:21:09,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001646-0000000000000001647_0000000000161258030 size 0 bytes.
2018-09-20 11:21:09,508 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-20 11:21:09,509 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001646-0000000000000001647 expecting start txid #1646
2018-09-20 11:21:09,509 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001646-0000000000000001647
2018-09-20 11:21:09,510 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001646-0000000000000001647 of size 42 edits # 2 loaded in 0 seconds
2018-09-20 11:21:09,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001647 using no compression
2018-09-20 11:21:09,523 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001647 of size 13498 bytes saved in 0 seconds.
2018-09-20 11:21:09,528 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1645
2018-09-20 11:21:09,528 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001643, cpktTxId=0000000000000001643)
2018-09-20 11:21:09,540 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1647 to namenode at http://localhost:50070 in 0.006 seconds
2018-09-20 11:21:09,540 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
2018-09-20 13:26:28,373 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-20 13:26:28,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1648&endTxId=1649&storageInfo=-63:535595440:1536283484232:CID-8b53fcda-6caa-40f2-846e-67a89cbec17e
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001648-0000000000000001649_0000000000164862169 size 0 bytes.
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001648-0000000000000001649 expecting start txid #1648
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001648-0000000000000001649
2018-09-20 13:26:28,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jason/dfs/namesecondary/current/edits_0000000000000001648-0000000000000001649 of size 42 edits # 2 loaded in 0 seconds
2018-09-20 13:26:28,381 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001649 using no compression
2018-09-20 13:26:28,385 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jason/dfs/namesecondary/current/fsimage.ckpt_0000000000000001649 of size 13498 bytes saved in 0 seconds.
2018-09-20 13:26:28,390 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1647
2018-09-20 13:26:28,390 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jason/dfs/namesecondary/current/fsimage_0000000000000001645, cpktTxId=0000000000000001645)
2018-09-20 13:26:28,404 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1649 to namenode at http://localhost:50070 in 0.008 seconds
2018-09-20 13:26:28,405 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13498
